\documentclass{article}

\input{preamble.tex}
\usepackage{enumitem}

\begin{document}

\title{A one phase IPM for non-convex optimization}
\author{Oliver Hinder, Yinyu Ye}

\algdef{SE}[SUBALG]{Indent}{EndIndent}{}{\algorithmicend\ }%
\algtext*{Indent}
\algtext*{EndIndent}

\maketitle

\newcommand{\yinyu}[1]{{\color{red} Yinyu: #1}}
\newcommand{\hinder}[1]{{\color{red}{Hinder: #1}}}

\newcommand{\algorithmicbreak}{\textbf{break}}
\newcommand{\obj}{f}
\newcommand{\cons}{a}
\newcommand{\nvar}{n}
\newcommand{\ncon}{m}
\newcommand{\parNumCor}{c_{\max}}
\newcommand{\parComp}{\beta_{1}}
\newcommand{\parCompAgg}{\beta_{2}}
\newcommand{\parMinStableStepSize}{\beta_{3}}
\newcommand{\parKKTReductFactor}{\beta_{4}}
\newcommand{\parObjReductFactor}{\beta_{5}}
\newcommand{\parBacktracking}{\beta_{6}}
%\newcommand{\parMinStepAgg}{\beta_{8}}
\newcommand{\parFracBoundary}{\beta_{7}}
\newcommand{\parFracBoundaryMax}{\beta_{8}}
\newcommand{\parFracBoundaryExp}{\beta_{9}}
\newcommand{\parRegularizer}{\beta_{10}}
\newcommand{\parConRegularizer}{\beta_{11}}
\newcommand{\parInitialize}{\beta_{12}}

%\newcommand{\parFilterReduceBarrier}{\beta_{13}}
%\newcommand{\parMaxRatioPrimalMu}{\beta_{14}}

\newcommand{\parDeltaMin}{\delta_{\min}}
\newcommand{\parDeltaIncreaseFailure}{\delta_{\text{inc}}}

%\newcommand{\Filter}{\mathbb{F}}
\newcommand{\History}{\mathbb{H}}
\newcommand{\conWeight}{w}
\newcommand{\ConWeight}{W}
\newcommand{\zeroSet}{Z}
\newcommand{\nonzeroSet}{N}
\newcommand{\alphaMinAgg}{\alpha_{\min}}
\newcommand{\vioVar}{\mu}
\newcommand{\barrier}{\psi}
\newcommand{\regularizer}{r}
\renewcommand{\R}{\mathbb{R}}
\newcommand{\schur}{\mathcal{M}}
%\newcommand{\schur}[1]{\mathcal{M}#1}
\newcommand{\MatrixSchur}[2]{\mathcal{H}_{#1}(#2)}


\newcommand{\termination}{\eqref{terminate-kkt}, \eqref{terminate-primal-infeasible} or \eqref{terminate-dual-infeasible}}
\newcommand{\infeasFunc}{\Gamma}


\newcommand{\TOLinf}{\epsilon_{\textbf{inf}}}
\newcommand{\TOLmu}{\epsilon_{\textbf{mu}}}
\newcommand{\TOLopt}{\epsilon_{\textbf{opt}}}
\newcommand{\TOLunbounded}{\epsilon_{\textbf{unbd}}}
\newcommand{\maxgrad}{G}


\newcommand{\status}{\textbf{status}}
\newcommand{\success}{\textsc{success}}
\newcommand{\failure}{\textsc{failure}}

\newcommand{\feasible}{\textbf{feasible}}

\newcommand{\meritKKT}{\mathbb{K}}

\newlength\myindent % define a new length \myindent
\setlength\myindent{6em} % assign the length 2em to \myindet
\newcommand\bindent{%
  \begingroup % starts a group (to keep changes local)
  \setlength{\itemindent}{\myindent} % set itemindent (algorithmic internally uses a list) to the value of \mylength
  \addtolength{\algorithmicindent}{\myindent} % adds \mylength to the default indentation used by algorithmic
}
\newcommand\eindent{\endgroup} % closes a group

% alg
\newcommand{\simpleIPM}{Simplified-One-Phase-Non-Convex-IPM}
\newcommand{\callSimpleIPM}{\Call{Simplified-One-Phase-Non-Convex-IPM}}

\newcommand{\backtrackBlurb}{\emph{Perform a backtracking line search on the primal step $\alpha_{P}$.} Trial step sizes $\alpha_{P} \in \{\alpha^{\max}_{P}, \parBacktracking \alpha^{\max}_{P}, \parBacktracking^2 \alpha^{\max}_{P}, ... \}$ computing the trial point $(x^{+}, y^{+}, s^{+}, \mu^{+})$ as described in \eqref{eq:iterate-update}. Terminate with $\status = \success$ and return the trial point the first time all of the following conditions hold:}


\begin{abstract}
The work of \cite{wachter2000failure} suggests that infeasible start interior point methods (IPMs) developed for linear programming cannot be adapted to non-linear optimization without significant modification i.e. using a two phase or a penalty method. We propose an IPM, that by careful initialization and updates of the slack variables, is guaranteed to find an first order certificate of local infeasibility, local optimal or unboundedness. Our proposed algorithm differs from other IPM methods for non-convex programming, because we reduce primal feasibility at the same rate as the barrier parameter. This gives an algorithm with more robust convergence properties and closely resembles successful algorithms from linear programming. We implement the algorithm and compare with IPOPT subset of CUTEst problems. Our algorithm requires has a similar median number of iterations, however, fails on only 9\% compared with 16\% for IPOPT. Experiments on infeasible variants of CUTEst indicate superior performance for detecting infeasibility.

%We require less iterations on Z\% of the problems and our algorithm fails only on X\% of the problems compared with Y\% for IPOPT.
\end{abstract}

\section{Introduction}

This paper develops an interior point method for finding stationary points of the problem:
\begin{flalign}\label{original-problem} 
\min_{x \in \R^{\nvar}}{f(x)} \\
a(x) \le 0,
\end{flalign}
where the functions $a(x) : \R^{\nvar} \rightarrow \R^{\ncon}$ and $f : \R^{\nvar} \rightarrow \R$ are twice differentiable and might be non-convex. Examples of real world problems in this framework include truss design, robot control, aircraft control and aircraft design e.g. the problems TRO11X3, ROBOT, AIRCRAFTA, AVION2 in CUTEst \cite{gould2015cutest}. 

Interior point methods were first developed for linear programming \cite{karmarkar1984new}. The idea for primal-dual interior point methods originates with \cite{megiddo1989pathways}. Initially, algorithms that required a feasible starting point were studied \cite{kojima1989primal,monteiro1989interior}. However, generally one is not given an initial point that is feasible. A naive solution to this issue is to move the constraints into the objective  by adding a large penalty for constraint violation (Big-M method) \cite{mcshane1989implementation}. A method to avoid the penalty approach, with a strong theoretical foundation for linear programming, is the homogenous algorithm \cite{ye1994nl,andersen1999homogeneous,andersen1998computational}. The homogenous algorithms measures progress in terms of the KKT error, which may not monotonically decrease in the presence of non-convexity \hinder{ref appendix or something}. For this reason, the homogenous algorithm is difficult to generalize to non-linear optimization. An alternate to the homogenous algorithm is the infeasible start algorithm of \cite{lustig1990feasibility} which has less numerical issues and a smaller iteration count than the big-M method of \cite{mcshane1989implementation}. This approach also simplified the algorithm, by avoiding the need to make a good initial guess for the size of the penalty parameters. Lustig's approach was further improved in the predictor-corrector algorithm of \cite{mehrotra1992implementation}. This algorithm reduced complementarity, duality and primal feasibility at the same rate, using an adaptive heuristic. This class of methods was shown by \cite{todd2003detecting} to converge to either optimality or infeasibility certificates (of the primal or dual). 

%This infeasible start algorithm was combined with predictor-corrector technique of Mehrotra \cite{ye1993quadratic} into an algorithm with excellent practical performance. 

This infeasible start approach of \cite{lustig1990feasibility} for linear programming naturally extends to non-linear optimization. 
\yinyu{A good example to cite is:
`An infeasible interior-point algorithm for solving primal and dual geometric programs', (Kortanek, Xu, and Ye),
Math Programming 76 (1997) 155-182.} \hinder{discuss this reference with yinyu}
And most interior point codes for non-convex optimization are built off these ideas \cite{vanderbei1999loqo,wachter2006implementation,byrd2006knitro}. However, \cite{wachter2000failure} showed for the problem
\begin{subequations}\label{failure-ex}
\begin{flalign}
\min { x }\\
x^2 - s_1 - 1 &= 0 \\
x - s_2 - 1/2 &= 0 \\
s_1, s_2 &\ge 0,
\end{flalign}
\end{subequations}
a large class of infeasible start algorithms fails to converge to either a local optimum or infeasibility certificate starting at any point with $x < 0$, $s_{1}, s_{2} > 0$. Following this paper, a flurry of research was published suggesting different methods for resolving this issue \cite{benson2004interior}. The main two approaches can be split into penalty methods \cite{liu2004robust, chen2006interior,curtis2012penalty,gould2015interior} and two phase algorithms \cite{wachter2006implementation}. 

Penalty methods move some measure of constraint violation into the objective. These methods require a penalty parameter $M$ that measures how much the constraint violation contributes to the objective. For large enough $M$ the algorithm will converge to an optimal solution. However, estimating this penalty parameter is difficult -- too small and the algorithm will not find a feasible solution, too big and the algorithm might be slow and suffer from numerical issues. Consequently, typically penalty methods tend to be slow \cite[Algorithm 1]{curtis2012penalty} or use complex schemes for dynamically updating the penalty parameter \cite[Algorithm 2]{curtis2012penalty}. 

The algorithm IPOPT is an example of a two phase algorithm: it has a main phase and a feasibility restoration phase  \cite{wachter2006implementation}. The main phase searches simultaneously for optimality and feasibility using a classical infeasible start method. The other phase, known as the feasibility restoration phase, aims to minimizes infeasibility. The feasibility restoration phase is only called when the main phase fails e.g. the step size is small. It is well-known that this approach has drawbacks. The algorithm has difficulties detecting infeasibility \cite[Table 15]{huang2016solution} and will fail if the feasibility restoration phase is called too close to the optimal solution. Some of these issues have been addressed by \cite{nocedal2014interior}. 

The main contribution of this paper is an infeasible start method interior point method for non-linear programming that builds on the work of \cite{lustig1990feasibility, mehrotra1992implementation} for linear programming. The algorithm avoids a big-M or a two phase approach. Furthermore, our solution to the issue in example \eqref{failure-ex} of \cite{wachter2000failure} is simple: we carefully initialize the slack variables and use non-linear updates to ensure we approach feasibility from above. Consequently, under general conditions we guarantee that our algorithm will converge to either a local certificate of optimality, local infeasibility or unboundedness. Our algorithm has other desirable properties. Complementarity moves at the same rate as primal feasibility. This implies from \cite{lagIPM} that, if certain sufficient conditions for local optimality conditions hold, our approach guarantees dual multipliers sequence will remain bounded. In contrast, methods that reduce the primal feasibility too quickly, such as IPOPT,  the dual multiplier sequence can be unbounded even for linear programs.

%From \cite{lagIPM} we know that if certain sufficient conditions for local optimality conditions hold, then a subsequence of the dual multipliers will converge if the primal solution is converging to a KKT point. Consequently, our algorithm may find finite dual multipliers, even if the set of dual multipliers at the KKT point is unbounded. Conversely, methods that reduce the primal feasibility too quickly, such as IPOPT, will suffer from divergent dual multipliers \cite{lagIPM}.

\hinder{talk about dual vs primal}

Our method has further similarities with Mehrotra's \cite{mehrotra1992implementation} predictor-corrector algorithm for linear programming: the rate that we reduce the dual feasibility, primal feasibility and complementarity is adaptive \hinder{cite the adaptive andreas paper}. We implement the algorithm and compare our solver with IPOPT on large scale CUTEst problems. Our algorithm has a similar median number of iterations to IPOPT, however, seems to fail less often. Experiments on infeasible variants of CUTEst indicate superior performance for detecting infeasibility.

The paper is structured as follows: Section~\ref{sec:basic-alg} describes the algorithm, Section~\ref{sec:theory} gives the convergence proofs, Section~\ref{sec:implementation-details} delves into implementation details and Section~\ref{sec:empirical-results} presents test results on the CUTEst test set.


{\color{red}
\begin{enumerate}
\item talk about sequence stuff or MFCQ [MOVE??]
\item talk about filter methods and how people observed better performance by avoiding penalty functions (so they take bigger steps)
\end{enumerate}
}


%may cycle between the feasibility restoration and optimality phases. Furthermore, if the feasibility 

\section{The algorithm}\label{sec:basic-alg}


Consider a naive log barrier problems of the form:
\begin{flalign} \label{naive-log-barrier}
\min_{x \in \R^{\nvar}}{f(x) - \mu \sum_i{ \log{(-a_i(x))} } }
\end{flalign}
The idea is to solve sequence of these sub-problems with $\mu \rightarrow 0$ and $\mu \ge 0$. The log barrier transforms the non-differentiable original problem~\eqref{original-problem} into a twice differentiable log barrier function on which we can apply newton's method. However, there are issues with this naive log barrier formulation. We are rarely given a feasible starting point. Furthermore, one would like to ensure that the primal and dual variables remain bounded. To resolve these issues we consider the shifted and regularized sub-problem described as follows:
%Therefore we shift the constraints, problem and gradually reduce the
% in the primal feasibility at each iteration. This is known shifted barrier formulation is given as follows:
\begin{flalign}
\min_{x \in \R^{\nvar}} \barrier_{\mu}(x) := f(x) + \mu r(x)  - \mu  \sum_i{ \log \left( \vioVar \conWeight_i - a_i(x)  \right) } \label{shifted-barrier-problem}
\end{flalign}
With some vector $\conWeight \ge 0$ which remains fixed for all sub-problems, and some $\vioVar > 0$ which measures the size of the shift. The function $\regularizer : \R^{\nvar} \rightarrow \R$ is define by:
\begin{flalign}\label{def:regularizer}
\regularizer(x) := \parRegularizer \sum_{i = 1}^{\nvar} \sqrt{x_i^2 + 1 / \parRegularizer^2} - \parConRegularizer e^T a(x).
\end{flalign}
where $\parRegularizer, \parConRegularizer \in (0,1)$ are constants. Note that $\mu \rightarrow 0$ the impact of the regularizer $\regularizer$ diminishes. The regularizer enables us to guarantee that if the norm of the primal iterates diverges towards infinity then the function $f(x)$ tends towards negative infinity (Theorem~\ref{thm:global-convergence}). Without the regularizer the primal iterates may unnecessarily diverge. For example, consider the problem $\min{ 0 } \text{ s.t. }  x \le 0$. In which case, with $\parRegularizer  = \parConRegularizer = 0$, the function $\barrier_{\mu}(x) = - \mu \log(\mu - x)$ has an optimal solution at $x = -\infty$. We remark with $\parRegularizer = 0$ and $\parConRegularizer > 0$ that this is a similar modification of log barrier function to previous works \hinder{more refs} \cite[Section 3.7]{wachter2006implementation}.
%\todo{say something more vague or cite theorem}
%As  $\mu \rightarrow 0$ convergent sequence of KKT solutions with $\mu \rightarrow 0$ to the shifted barrier problem \eqref{shifted-barrier-problem} will converge towards a KKT solution of the original problem.
%\todo{Comment about importance of non-linear updates and intialization}


Holistically, our technique consists of computing two types of directions: stabilization and aggressive directions. Both of these directions are computed from the same linear system with different right hand sides. Aggressive directions are equivalent to affine scaling steps \cite{mehrotra1992implementation}; since they apply a newton step directly to the KKT system, ignoring the barrier parameter $\mu$. Aggressive steps aim to simultaneously approach optimality and feasibility. However, continuously taking aggressive steps may cause the algorithm to stall or fail to converge. To remedy this we have a stabilization step. The stabilization steps keeps the primal feasibility the same i.e. uses $\eta = 0$ and aims to reduce the log barrier objective until an approximate solution to the shifted log barrier problem is found. While this step has similar goals to the centering step of Mehrotra there are distinct differences. The centering steps of Mehrotra move the iterates towards the central path, while keeping the primal and dual feasibility fixed. However, our stabilization steps only keep the primal feasibility fixed, while reducing the log barrier objective. This choice reflects challenges that occur in non-convex optimization and will be discussed more in \hinder{what challenges?}

\yinyu{The stabilization and aggressive steps here are exactly the corrector and predictor steps of Todd and Ye, where $\eta=0$ or $\eta=1$ alternatively. Mehrotra's techniques always select $\eta$ strictly between 0 and 1 by cleverly exploring affine direction and there is no alternation as we did in the current paper.}

%Section~\ref{sec:convergence-proofs}. 

The interior point method that we develop generates a sequences of primal iterates $x^{k}$, $s^{k} \in \R^{\nvar}$ with $s^k > 0$, barrier parameter $\mu^k > 0$ and feasibility violation $\vioVar^k > 0$ that satisfy:
\begin{subequations}\label{eq:barrier-primal-sequence-nice}
\begin{flalign}
a(x^{k}) + s^{k} &= \mu^k \conWeight \label{eq:primal-feasibility} \\
%\theta^{k} / \mu^{k} &= \theta^{0} / \mu^{0} \\ %\theta^{0} / \mu^{0} \text{??? maybe just write an interval here} \\
\frac{S^{k} y^{k}}{\mu^{k}} &\in [ e \parComp, e / \parComp],\label{eq:comp-slack} 
\end{flalign} 
\end{subequations}
Where $\conWeight \ge 0$ is vector selected such that at the initial point $a(x^{0}) + s^{0} = \vioVar^0 \conWeight$ and $\parComp \in (0,1)$ is an algorithmic parameter. This set of equations implies the primal feasibility and complementarity are moved at the same rate. Furthermore, there exists a subsequence of the iterates (those that satisfy the aggressive step criterion \eqref{agg-criteron}) such that: %  i.e. $x^{k} \rightarrow x^{*}$ and $s^{k} \rightarrow s^{*}$
\begin{flalign}
\frac{\| \nabla_{x} \Lag(x^{k}, y^{k}) \|_{\infty}}{\mu^k(\| y^{k} \|_{\infty} + 1)} &\le 1, \label{eq:dual-feas}
\end{flalign}
where $\Lag (x, y) := f(x) + y^T a(x)$ is the Lagragian function. Equations \eqref{eq:barrier-primal-sequence-nice} and \eqref{eq:dual-feas} holding is common in many practical linear programming implementations \cite{mehrotra1992implementation, more}. These conditions holding is desirable, because it implies the dual variables likely remained bounded. To be more precise, assume the subsequence satisfying \eqref{eq:barrier-primal-sequence-nice} and \eqref{eq:dual-feas} is converging to a feasible solution. If this solution satisfies certain sufficiency conditions for local optimality, then as shown our related paper \cite{lagIPM} the dual variables will remain bounded. Note that \eqref{eq:barrier-primal-sequence-nice} and \eqref{eq:dual-feas} can be interpreted as a `central sequence'. This is weaker than the existence of a central path, a concept from convex optimization \cite{megiddo1989pathways,andersen1999homogeneous}. Unfortunately, in non-convex optimization there may not exist a continuous central path (see Appendix~\ref{app:non-existence-of-central-path}).

Related to this property of the dual multipliers being well-behaved, is that that our algorithm is explicitly design for inequality constraints only. One can handle lower and upper bounds (or equalities) through this approach, while keeping the difficult of the factorization to the linear algebra  (Section~\ref{sec:linear-algebra}). The advantage of this approach is that it (i) enables this nice sequential properties to hold and (ii) we avoid the need for a second inertia modification parameter to ensure non-singularity of the linear system i.e. $\delta_{c}$ in equation~(13) in \cite{wachter2006implementation}. Avoiding the use of this $\delta_{c}$ removes issues where large modifications to the linear system may not provide a descent direction for the constraint violation. Therefore our approach simplifies the algorithm because there is no need for complicated schemes for choosing $\delta_{c}$. Furthermore, our approach naturally allows two options for computing the factorization and search directions, we can either (i) directly factorize the symmetric system~\eqref{eq:ldl-system} to compute $(d_{x},d_{y})$ using LDL, as is traditionally chosen by non-linear programming solvers or (ii) perform a Cholesky factorization of equation \eqref{eq:schur-matrix}, the primal schur complement. 

%This latter 
%\todo{
%interpretation of equality v.s. inequality constraints primal-dual methods 
%}

\subsection{Derivation of direction computation}\label{sub:direction-computation}

We cannot apply a newton method directly to problem \eqref{shifted-barrier-problem} without adding a proximal term \eqref{prox-obj} parameterized by $\delta$ and centered about the previous iterate $x$. This ensures the newton direction exists and is decreasing in the objective value for a fixed constraint violation i.e. $\eta = 0$. Therefore, we find the next iterate by approximately solving:

\begin{subequations}\label{sophisticated-barrier-problem}
\begin{flalign}
x^{*}, s^{*} \gets \arg \min_{\bar{x} \in \R^{\nvar}, \bar{s} \in \R^{\ncon++}} & f(\bar{x}) -(1 - \eta) \mu \left( -\regularizer( \bar{x} ) + \sum_i{ \log{\bar{s}_i} } \right)  + \frac{\delta}{2} \| \bar{x} - x \|^2 \label{prox-obj} \\
& a(\bar{x}) + \bar{s} = (1 - \eta) \mu \conWeight \\
& \bar{s} \ge 0.
\end{flalign}
\end{subequations}



Writing the first-order local optimality conditions for this problem gives:
\begin{flalign*}
\nabla_{x} \Lag(x^{*}, y^{*}) + \delta (x^{*} - x) &=  (1 - \eta) \mu \nabla \regularizer( x^{*} )  \\
a(x^{*}) + s^{*} &= (1 - \eta) \mu \conWeight \\
s_i^{*} y_i^{*} &= (1 - \eta) \mu \\
s^{*}, y^{*} &\ge 0
\end{flalign*} 
Primal interior point methods \cite{fiacco1990nonlinear} apply Newton's method directly to system \eqref{sophisticated-barrier-problem}. However, they have inferior practical performance to primal-dual methods, that apply newton's method directly to the optimality conditions. Therefore, we use primal-dual search directions defined as follows:
\begin{flalign}\label{primal-dual-newton-direction}
\mathcal{K}_{\delta} d = -b
\end{flalign}
where
\begin{flalign}
d &= \begin{bmatrix}
d_{x} \\
d_{y} \\
d_{s}
\end{bmatrix} 
\\
b &= \begin{bmatrix}
b_{D} \\
b_{P} \\
b_{\mu}
\end{bmatrix} = \begin{bmatrix}
 \nabla_{x} \Lag(x,y) + (1 - \eta) \mu \nabla r(x) \\
\eta  \mu \conWeight \\
Y s - \eta \mu e 
\end{bmatrix} \label{def:b} 
\\
\mathcal{K}_{\delta}
 &= \begin{bmatrix}
 \nabla^2_{x} \Lag(\hat{x},\hat{y}) + (1 - \hat{\eta}) \hat{\mu} \nabla^2 r(\hat{x}) + \delta I  & \nabla a(\hat{x})^T & 0  \\
\nabla a(\hat{x}) & 0 & I \\
0 & \hat{S} & \hat{Y}
\end{bmatrix}. \label{def:K-delta} 
\end{flalign}

For the first inner iteration we compute $\mathcal{K}_{\delta}$ we have $(\hat{x},\hat{y},\hat{s}) = (x,y,s)$. In subsequent inner iterations we recycle the factorization of $\mathcal{K}_{\delta}$ solving with new right hand side values. This reduces the number of outer iterations and hence the total number of factorizations. In regimes where the factorizing $\mathcal{K}_{\delta}$ is expensive this is beneficial. We use $\mathcal{K}_{\delta}^{-1}$ to denote this factorization of $\mathcal{K}_{\delta}$. Next, we show that one can implicitly form this factorization by computing an LDL factorization of a system in the variables $(d_{x},d_{y})$ or cholesky factorization of linear system in the variables $d_{x}$. Note that the matrix~\eqref{def:K-delta} is asymmetric. To obtain the system we can perform an LDL factorization, we eliminate $d_{s}$ from \eqref{primal-dual-newton-direction} to yield the following symmetric system:
\begin{flalign}\label{eq:ldl-system}
 \begin{bmatrix}
 \nabla^2_{x} \Lag(\hat{x},\hat{y}) + (1 - \hat{\eta}) \hat{\mu} \nabla^2 r(\hat{x}) + \delta I  & \nabla a(\hat{x})^T  \\
\nabla a(\hat{x}) & -\hat{Y}^{-1} \hat{S} \\
\end{bmatrix}
\begin{bmatrix}
d_{x} \\
d_{y}
\end{bmatrix} 
=
-\begin{bmatrix}
b_{D} \\
b_{P} - \hat{Y}^{-1} b_{\mu}
\end{bmatrix}.
\end{flalign}



By taking the primal schur complement one can see solving system \eqref{primal-dual-newton-direction} for $d_{x}$ is equivalent to solving:
\begin{flalign}\label{eq:schur-complement}
(\schur + \delta I)  d_{x} = -\left( b_{D} + \nabla a(\hat{x})^T \hat{S}^{-1} \left( \hat{Y} b_{P} - b_{\mu} \right) \right)
%- \nabla f(x) - \nabla a(x)^T ((1 - \eta) \mu S^{-1} e + \eta Y ( e +  \mu S^{-1}\conWeight ) - \mu (1 - \eta) \nabla r(x).
\end{flalign}
where the matrix $\schur$ is
\begin{flalign}\label{eq:schur-matrix}
\schur = \nabla^2_{x} \Lag (\hat{x}, \hat{y}) + (1 - \hat{\eta}) \hat{\mu} \nabla^2 r(\hat{x})  + \nabla a(\hat{x})^T \hat{Y} \hat{S}^{-1} \nabla a(\hat{x}),
\end{flalign}
is a primal-dual approximation of the hessian of the log barrier function $ \barrier_{\mu}(x)$. We can factorize the matrix using a Cholesky decomposition.

Note that if the matrix $(\schur + \delta I)$ is positive definite, $\eta = 0$ and $(\hat{x},\hat{y},\hat{s}) = (x,y,s)$ then the right hand side of \eqref{eq:schur-complement} becomes $-\nabla \barrier_{\mu}(x)$ hence the direction $d_{x}$ is a descent direction on the function $\barrier_{\mu}(x)$. Consequently, during our algorithm we will pick $\delta > 0$ such that  the matrix $(\schur + \delta I)$ is positive definite. Aside from performing a Cholesky factorization of $(\schur + \delta I)$, we can also determine that the matrix is positive definite by computing the number of positive and negative elements in the diagonal of the LDL factorization of \eqref{eq:ldl-system}. A more indepth discussion of the linear algebra details will be given in Section~\ref{sec:linear-algebra}.

\hinder{be careful with $\nabla^2 r(x)$.}


\subsection{Updating the iterates}

Suppose that we have computed some direction $d$ by solving system \eqref{primal-dual-newton-direction}. We wish to construct a candidate $(x^{+}, s^{+}, y^{+}, \mu^{+})$ for the next iterate.
Given a primal step size $\alpha_{P}$ we update the primal iterates as follows:
\begin{subequations}\label{eq:iterate-update}
\begin{flalign}
\mu^{+} &\gets (1 - \eta \alpha_{P}) \mu \\
%\vioVar^{+} &\gets (1 - \eta \alpha_{P}) \vioVar \\
x^{+} &\gets x + \alpha_{P} d_{x} \label{eq:xVarUpdate} \\
s^{+} &\gets \vioVar^{+} \conWeight - a(x^{+}) \label{eq:slackVarUpdate}
\end{flalign}
\end{subequations}
The slack variable update \eqref{eq:slackVarUpdate} is non-linear and its purpose is to ensure that equation~\eqref{eq:primal-feasibility} remains satisfied and therefore we can control the rate of reduction of primal feasibility. However, if the function $a$ is linear the slack variable update~\eqref{eq:slackVarUpdate} reduces to:
$$
s^{+} = \vioVar^{+} \conWeight - a(x) - \alpha_{P} \nabla a(x)  d_{x} = \left(\vioVar \conWeight - a(x) \right) -  \alpha_{P}  \left( \eta \vioVar \conWeight + \nabla a(x)  d_{x} \right) = s + \alpha_{P} d_{s}
$$
Therefore if the function $a$ is linear we use the same updates as infeasible start algorithms for linear programming \cite{lustig1990feasibility,mehrotra1992implementation}. Non-linear updates for the slack variables have been used in other interior point methods \cite{andersen1998computational, curtis2012penalty}.

Next, we specify a criterion to prevent the slack variables from getting too close to the boundary. In particular, given any candidate primal iterate $(x^{+}$, $s^{+})$ we require that the following fraction to the boundary rule is satisfied:
\begin{flalign}\label{fracBoundary}
s^{+} \ge  \parFracBoundary \min\{ s, \| d_{x} \|_{\infty}^2 \} 
\end{flalign}

Finally, it remains to desribe how to update the dual variables. Given some candidate primal iterate $x^{+}$, $s^{+}$, then let $B( s^{+}, d_{y} )$ be the set of feasible dual step sizes. More precisely, $B( s^{+}, d_{y} )$ is the largest interval such that if $\alpha_{D} \in B( s^{+}, d_{y} )$ then
\begin{subequations}\label{subeq:set-B}
\begin{flalign}
 \frac{S^{+} (y + \alpha_{D} d_{y})}{\mu^{+}} &\in [e \parComp, e/\parComp ]. \label{satisfy-comp} %\\
% y + \alpha_{D} d_{y} &\ge  \parFracBoundary \min\{ y ,  \| d_{x} \|_{\infty}^2 \}.
\end{flalign}
\end{subequations}
If there is no value of $\alpha_{D}$ satisfying \eqref{subeq:set-B} we set $B( s^{+}, d_{y} )$ to the empty set and the step will be rejected. The purpose criteria \eqref{subeq:set-B} is to ensure we always satisfy \eqref{eq:comp-slack} i.e. $\frac{S y}{\mu} \in [e \parComp, e/\parComp ]$.


 We compute the dual step size as follows:
\begin{flalign}
\alpha_{D} = \arg \min_{\alpha_{D} \in B( s^{+}, d_{y} )} \| S^{+} y - \mu^{+} + \alpha_{D} S^{+} d_{y} \|^2_{2} + \| \nabla_{x} \Lag(x, y)  + (\nabla_{x}^2 \Lag(x, y) + \delta I) \alpha_{P} d_{x}  +\alpha_{D}  \nabla a(x)^T d_{y} \|^{2}_{2}.
\label{eq:alphaD-least-squares}
\end{flalign}

This reduces to a one dimensional least squares problem in $\alpha_{D}$ which has a closed form expression. Equation~\eqref{eq:alphaD-least-squares} can be interpreted choosing the step size $\alpha_{D}$ to approximately minimize the dual feasibility of the proximal sub-problem. This encourages large dual step sizes without forgoing information about dual feasibility. 

\subsection{Termination criterion}

Now, we have derived the primal infeasibility termination criterion we can present the termination criterion for our algorithm. Define the following function $\sigma$,
$$
\sigma (y) := \frac{100}{\max\{ 100, \| y \|_{\infty} \}}
$$
which is a scaling factor based on the size of the dual variables. This scaling factor is related to $s_{d}$ and $s_{c}$ in the IPOPT implementation paper \cite{wachter2006implementation}. We use $\sigma(y)$ in the local optimality termination criterion \eqref{terminate-kkt} because there may be numerical issues reducing the unscaled dual feasibility if the dual multipliers become large. In particular, the first order optimality termination criterion we use is:
\begin{subequations}\label{terminate-kkt}
\begin{flalign}
\sigma (y) \| \nabla \Lag(x, y) \|_{\infty} &\le  \TOLopt  \\
\sigma (y) \| S y \|_{\infty} &\le \TOLopt  \\
\| a(x) + s \|_{\infty} &\le \TOLopt.
\end{flalign}
\end{subequations}
The first order local primal infeasibility termination criterion is given by:
\begin{flalign}\label{terminate-primal-infeasible}
\infeasFunc (x,y,s, \vioVar) \le \TOLinf
\end{flalign}
where
\begin{flalign}\label{def:infeasFunc}
\infeasFunc (x,y,s, \vioVar) :=  \frac{\max \{ \| \nabla a(x)^T y \|_{\infty}, \| S y \|_{\infty} \}}{ \| Y\conWeight\|_{\infty} \min\{  1, \vioVar \}}.
\end{flalign}
We remark that if we find a point with $\infeasFunc (x,y,s, \vioVar) = 0$ then we have found a stationary point to a weighted $L_{\infty}$ infeasibility measure.
For a more thorough justification of this choice for the infeasibility termination criterion see Section~\ref{sec:infeas-criteron-justify}.

The unboundedness termination criterion is given by
\begin{flalign}\label{terminate-dual-infeasible}
\frac{\max\{ \| a(x)^{+} \|_{\infty}, 1 \}  }{\min\{ \max\{1,-f(x) \} \}, \| x \|_{\infty} \}} \le \TOLunbounded.
\end{flalign}
\hinder{does this match the proofs???}

Satisfying this termination criterion for arbitrary small $ \TOLunbounded$ does not guarantee that the problem has an objective that is unbounded from below on the feasible region. However, if the functions $f$ and $a$ are convex, and there exists a strictly feasible solution, then if the criterion is satisfied as $\TOLunbounded \rightarrow 0$ one can conclude the objective is unbounded from below on the feasible region.

\subsection{Algorithm outline}

Before we outline our algorithm, we need to define the switching condition when take an aggressive direction instead of a stabilization step, which we define as follows:
\begin{subequations}\label{agg-criteron}
\begin{flalign}
\sigma (y) \| \nabla \Lag(x, y) \|_{\infty} &\le \mu   \label{agg-criteron-opt} \\
\| \nabla \Lag(x, y) \|_{\infty} &\le  \max\{ \| \nabla f(x) \|_{\infty},  \mu / \parCompAgg \} \label{agg-criteron-farkas} \\
 \frac{S y}{\mu} &\in [ e \parCompAgg, e / \parCompAgg ]. \label{agg-criteron-buffer}
\end{flalign}
\end{subequations}
where the parameter $\parCompAgg \in (\parComp, 1)$. The purpose of \eqref{agg-criteron-opt} is to ensure that we have approximately solved the shifted log barrier problem. Equation~\eqref{agg-criteron-farkas} also helps ensure (as we show in Section~\ref{sec:global-conv}) that if the dual variables are diverging rapidly then the infeasibility termination criterion is met. Finally, equation~\eqref{agg-criteron-buffer} with $\parCompAgg > \parComp$ ensures we have some a buffer in the complementarity such that we can still satisfy \eqref{satisfy-comp} when we move in the aggressive search direction. Algorithm~\ref{one-phase-IPM} formally outlines our one phase interior point method. Note that Algorithm~\ref{one-phase-IPM} does not include the details for the aggressive or stabilization steps that are given in Algorithm~\ref{alg:aggressive} and Algorithm~\ref{alg:stable} respectively. Since Algorithm~\ref{one-phase-IPM} maintains $a(x) + s = \conWeight \vioVar$ for each iterate, it requires the starting point satisfies:
$$
a(x^{0}) + s^{0} = \conWeight \vioVar^{0},
$$
with $\conWeight \ge 0$ and $\vioVar^{0} > 0$. For any fixed $x^{0}$ one can always pick sufficiently large $\conWeight$ and $\mu^{0}$ such that $\mu^{0} \conWeight > a(x^{0})$ and setting $s^{0} \gets \conWeight \vioVar^{0} - a(x^{0})$ meets our requirements. For the details of how initialize the variables in the practical implementation see Section~\ref{sec:initialization}.

The general idea of Algorithm~\ref{one-phase-IPM} is as follows. At each outer iteration we factorize the matrix $\mathcal{K}_{\delta}$ with an appropriate choice of $\delta$ using Algorithm~\ref{alg:mat-fact} (based off ideas of IPOPT). With this factorization fixed, we then attempt to take multiple inner iterations (at most $\parNumCor$), which corresponds solving system~\eqref{primal-dual-newton-direction} with different right hand sides choices, but the same matrix $\mathcal{K}_{\delta}$. Each inner iterations is either an aggressive or stabilization steps. If, on the inner iteration, the step fails (i.e. due to a too small step size), then we increase $\delta$ to address this failure and re-factorization $\mathcal{K}_{\delta}$. Note that we evaluate the Hessian of the Lagrangian and the full Jacobian once per outer iteration (we do one Jacobian-vector product per inner iteration). Furthermore, the selection of the initial point $(x^{0}, y^{0}, s^{0}, \mu^{0})$ is described in Section~\ref{sec:initialization}.

%\hinder{explain that the selection of the initial point is addressed later}
%it is suffices to choose $\mu^{0} \conWeight > a(x^{0})$, although we choose $\conWeight_i = 1$ for

\begin{algorithm}[H]
\textbf{Input:} some initial point $x^{0}$, vector $\conWeight \ge 0$ and variables $y^{0}, s^{0}, \mu^0 > 0$  such that $a(x^{0}) + s^{0} = \conWeight \vioVar^{0}$ and equation~\eqref{eq:comp-slack} with $k=0$ is satisfied. Termination tolerances $\TOLinf$, $\TOLunbounded, \TOLinf > 0$. \\
\textbf{Output:} some point $(x, y, s, \mu)$ that satisfies the termination criterion (inequalities \termination{}) 
\vspace{0.1 cm} \\
\emph{For each outer iteration $i \in \{1, \dots, i_{\max}\}$ perform the following steps:}
\begin{enumerate}[label*=A.{\arabic*}]
\item \label{step-1}  \emph{Evaluate the matrix Hessian of the Lagrangian $\nabla^2_{x} \Lag(x,y)$ and the Jacobian of the constraints $\nabla a(x)$.}
\item \label{line:form-K}  \emph{Form the matrices $\mathcal{K}_{0}$ and $\schur$ using \eqref{def:K-delta} and \eqref{eq:schur-matrix} respectively, at the point $(\hat{x}, \hat{y}, \hat{s}, \hat{\mu}) \gets (x, y, s, \mu)$ with $\hat{\eta} = 1$ if the aggressive step criterion~\eqref{agg-criteron} is satisfied and $\hat{\eta} = 0$ otherwise.}
%\item \emph{Form primal schur complement at the current point $\schur$ via \eqref{}.}
\item \emph{Select $\delta$ and factorize the matrix $\mathcal{K}_{\delta}$,} \\
i.e. run Algorithm~\ref{alg:mat-fact} with: \\
\hspace*{0.1cm}  \textbf{Input:} $\mathcal{K}_{0}$, $\delta$. \\
\hspace*{0.1cm} \textbf{Output:} New value for $\delta$, factorization $\mathcal{K}_{\delta}^{-1}$.
\item \label{take-steps}  \emph{Perform inner iterations where we recycle the factorization of $\mathcal{K}_{\delta}$.} \\
For $j \in \{ 1, \dots , \parNumCor \}$ do:
\begin{enumerate}[label*=.{\arabic*}]
\item \emph{Take step}\label{line:take-step}
\begin{enumerate}[label=-Case-{\Roman*}]
\item If the aggressive step criterion~\eqref{agg-criteron} is satisfied, do an aggressive step, \\
i.e. run Algorithm~\ref{alg:aggressive} with: \\
\hspace*{0.1cm}  \textbf{Input:} $\mathcal{K}_{\delta}, \mathcal{K}_{\delta}^{-1}$ and the point $(x,y,s, \mu)$. \\
\hspace*{0.1cm}  \textbf{Output:} A $\status$ and a new point $(x^{+},y^{+},s^{+}, \mu^{+})$.
\item Otherwise, do a stabilization step, \\
i.e. run Algorithm~\ref{alg:stable} with: \\
\hspace*{0.1cm} \textbf{Input:} $\mathcal{K}_{\delta}, \mathcal{K}_{\delta}^{-1}, \schur$ and the point $(x,y,s, \mu)$. \\
\hspace*{0.1cm} \textbf{Output:} A $\status$ and a new point $(x^{+},y^{+},s^{+}, \mu^{+})$.
\end{enumerate}
\item \emph{Deal with failures}. If $\status = \success$ set $(x, y, s, \mu) \gets (x^{+},y^{+},s^{+}, \mu^{+})$. If $\status = \failure$ and $j = 1$ go to \eqref{increase-delta-for-failure}.  If $\status = \failure$ and $j > 1$ go to go to step~\eqref{step-1}.
\item \emph{Check termination criterion}. If any of the inequalities \termination{} hold at the point $(x,y,s,\mu)$ terminate the algorithm.
\end{enumerate}
\item 
Go to \eqref{step-1}.
\item \label{increase-delta-for-failure} \emph{Increase delta to address failure}. Set $\delta = \max\{\parDeltaIncreaseFailure \delta, \parDeltaMin \}$ and factorize the matrix $\mathcal{K}_{\delta}$. Go to step \eqref{take-steps}.
\end{enumerate}
\caption{High level description of one phase IPM}\label{one-phase-IPM}
\end{algorithm}

In both the aggressive steps and stabilization steps we use a backtracking line search. 
We choose the initial trial primal step size $\alpha_{P}^{\max}$ to be the maximum $\alpha_{P} \in [0,1]$ that satisfies the following fraction to the boundary rule:
\begin{flalign}\label{fracBoundaryPrimalMax}
s + \alpha_{P} d_{s} &\ge  \parFracBoundaryMax  \min\{ s, \max\{ \| d_{x} \|_{\infty}^2 , \| d_{x} \|_{\infty}^{\parFracBoundaryExp} \} \} 
\end{flalign}
where the parameter $\parFracBoundaryMax \in (\parFracBoundary, 1)$ and $\parFracBoundaryExp \in (1,2)$. The idea of this choice for $\alpha_{P}^{\max}$ is that the fraction to the boundary rule \eqref{fracBoundary} is likely to be satisfied for the first trial point i.e. $\alpha_{P} = \alpha_{P}^{\max}$. This is because:
$$
\parFracBoundaryMax  \min\{ s, \max\{ \| d_{x} \|_{\infty}^2 , \| d_{x} \|_{\infty}^{\parFracBoundaryExp} \} \} > \parFracBoundary \min\{ s, \| d_{x} \|_{\infty}^2 \} 
$$
corresponding to the right hand side of equation~\eqref{fracBoundaryPrimalMax} and equation~\eqref{fracBoundary} respectively.

\subsection{Aggressive steps}

Recall that when computing aggressive search directions we solve the system~\eqref{primal-dual-newton-direction} with $\eta = 1$, that is, we aim for both feasibility and optimality simultaneously. We accept any step size assuming it satisfies the fraction to the boundary rule \eqref{fracBoundary} and the set of valid dual step sizes are non-empty $B( s^{+}, d_{y} ) \neq \emptyset$ (see equations~\eqref{subeq:set-B}). 

The backtracking line search of the aggressive step has a minimum step size. If during the backtracking line search (line~\ref{agg:back-track} of Algorithm~\ref{alg:aggressive}) the step size $\alpha_{P}$ satisfies:
 \begin{flalign}\label{min-step-size-aggresssive}
\alpha_{P} \le \min_{i \in \{ 1, ..., \ncon \} : \conWeight_i > 0}{\frac{\parBacktracking \theta s_{i}}{2 \vioVar \conWeight_i} } ~~ \text{with} ~~ \theta = \min\left\{ \frac{\parComp - \parCompAgg}{\parCompAgg}, 1 - \parFracBoundary \right\}
%\parMinStepAgg \times \min_{\{ j : a_j(x) + s_j < 0 \}}{ \frac{ -s_j }{ a_j(x) + s_j} },
\end{flalign}
then we immediately reject the step and exit Algorithm~\ref{alg:aggressive}. Following this, $\delta$ is increased in Line~\ref{increase-delta-for-failure} of Algorithm~\ref{one-phase-IPM} and a new aggressive step is attempted. It is possible that $\delta$ will be increased many times, however, for sufficiently large $\delta$ an acceptable step will be found (see Lemma~\ref{lemma:agg-succeeds}). 


\begin{algorithm}[H]
\textbf{Input:} The point $(x,y,s, \mu)$, the matrix $\mathcal{K}_{\delta}$ and its factorization $\mathcal{K}_{\delta}^{-1}$. \\
%Some point $p = (x, y, s, \mu)$. The matrix from the linear system~\eqref{primal-dual-newton-direction} factorized (not necessarily at the point $p$) and a corresponding inertia modification $\delta$. \\
\textbf{Output:} A new point $(x^{+}, y^{+}, s^{+}, \mu^{+})$ and a $\status$ of either $\success$ or $\failure$
\begin{enumerate}[label*=A.{\arabic*}]
\item Compute the vector $b$ at the point $(x,y,s, \mu)$ via \eqref{def:b} with $\eta = 1$.
\item Solve the system $\mathcal{K}_{\delta} d = -b$.
\item Estimate the largest primal step size $\alpha^{\max}_{P}$ from equation~\eqref{fracBoundaryPrimalMax}.
\item \label{agg:back-track} \backtrackBlurb
\begin{enumerate}[label=({\roman*})] 
\item The fraction to the boundary rule \eqref{fracBoundary} is satisfied
\item The set of valid dual step sizes is non-empty i.e. $B( s^{+}, d_{y} ) \neq \emptyset$ 
%\item If either fraction to the boundary rule \eqref{} is satisfied or $\meritKKT_{\mu} ( x^{+}, y^{+}, s^{+} )  \le \beta (\| a(x^{+}) + s^{+} \|_{\infty} + \| a(x^{+}) + s^{+} \|_{\infty}^{1/2}) $
\end{enumerate}
Terminate with $\status = \failure$ if the line search step size with \eqref{min-step-size-aggresssive} satisfied.
\end{enumerate}
\caption{High level description of aggressive step}\label{alg:aggressive}
\end{algorithm}


\subsection{Stabilization step}

\subsubsection{Augmented log barrier merit function}\label{sec:augmented-log-barrier}

When the stabilization step is called the goal is to minimize the function $\barrier_{\mu}$ keeping the constraint violation and barrier parameter fixed, until criterion~\eqref{agg-criteron} for an aggressive step is met. For this reason, it makes sense to use the log barrier function $\barrier_{\mu}$ to measure progress. We can approximate the change in the log barrier function by the following model:
\begin{flalign}
\tilde{\Delta}_{(x,y)}^{\barrier_{\mu}} ( u ) = \frac{1}{2} u^T \schur u + \nabla \barrier_{\mu}(x)^T u
\end{flalign}
where $\schur$ is computed on line~\ref{line:form-K} of Algorithm~\ref{one-phase-IPM}.

Note that if $\schur = \nabla^2_{\mu} \barrier(x)$ then $\tilde{\Delta}_{(x,y)}^{\barrier}$ becomes the second order taylor approximation of $\barrier_{\mu}$ at the point $x$. Thus, we can think of $\tilde{\Delta}_{(x,y)}^{\barrier} ( u )$ as a primal-dual approximation of the barrier function $\barrier_{\mu}$. Note that the log barrier function  does not measure anything with respect to the dual iterates. This might impede performance if $\| S y - \mu \|_{\infty}$ is large, but $\| \nabla \barrier_{\mu}(x) \|$ is small. In this case, taking a large step might reduce the complementarity significantly, even though the barrier function increases slightly. Therefore we add a complementarity measure to the barrier function to create an augmented log barrier function:
\begin{flalign}
\phi_{\mu}(x, y, s) := \barrier_{\mu}(x) + \MeritComp(s, y),
\end{flalign}
where
$$
\MeritComp(s,y) = \frac{\| S y - \mu \|_{\infty}^3}{\mu^2}.
$$
We can also build a model of the $\MeritComp(s,y) $ as follows:
\begin{flalign*}
\tilde{\Delta}^{\MeritComp}_{(x,y)}( u, v ) = \frac{\| S y + Y \nabla a(x) u + S v - \mu e \|_{\infty}^3 - \| S y - \mu  \|_{\infty}^3}{\mu^2}
\end{flalign*}
and our model of $\phi_{\mu}$ is
\begin{flalign}
\tilde{\Delta}^{\phi_{\mu}}_{(x,y)}(u, v) = \tilde{\Delta}^{\barrier_{\mu}}_{(x,y)}( u ) +   \tilde{\Delta}^{\MeritComp}_{(x,y)}( u, v ).
\end{flalign}



We say that the candidate iterates $x^{+}, y^{+}, s^{+}$ have made sufficient progress on $\phi$ over the current iterate $x, y, s$ if:
\begin{flalign}\label{phi-sufficient-progress}
\phi_{\mu}(x^{+}, y^{+}, s^{+}) \le \phi_{\mu}(x, y, s) + \parObjReductFactor \tilde{\Delta}^{\phi_{\mu}}_{(x,y)}(\alpha_{P} d_{x}, \alpha_{P} d_{y})
\end{flalign}
where $\parObjReductFactor \in (0,1)$ is a user defined parameter. 

\subsubsection{KKT merit function and filter}

In the stabilization search directions we accept steps that make progress one on of two merit functions, which form a filter. The first function $\phi_{\mu}$ is defined in Section~\ref{sec:augmented-log-barrier}. The second function, we call the KKT merit function, measures the scaled dual feasibility and complementary:
\begin{flalign}\label{merit-KKT}
\meritKKT_{\mu} ( x, y, s )  = \sigma( y ) \max\{ \| \nabla \Lag(x, y ) \|_{\infty},  \| S y - \mu \|_{\infty} \}
\end{flalign}
This merit function measures progress effectively in regimes where the matrix $\schur$ is positive definite. In this case, the search directions generated by \eqref{eq:schur-complement} will be a descent direction on this merit function\footnote{For inner iteration $j=1$}. This merit function is similar to the types of the potential functions used in interior point methods for convex optimization \cite{andersen1998computational,huang2016solution}. Unfortunately, while this merit function may be an excellent choice for convex problems, in non-convex optimization it has serious issues. In particular, the search direction \eqref{eq:schur-complement} will not be a descent direction on this merit function. Moreover, changing the search direction to minimize the dual feasibility has negative ramifications. The algorithm could to converge to a critical point of the dual feasibility where $\meritKKT_{\mu} ( x, y, s ) \neq 0$\footnote{To see why this occurs one need only consider an unconstrained problem e.g. minimizing the function $f(x) = x^4 + x^3 + x$ subject to no constraints. The point $x = 0$ is a stationary point for the gradient of $\nabla f(x)$, but is not a critical point of the function.}. For further discussion of these issues see \cite{shanno2000interior}.
%\cite{shanno1997interior}.


While it is sufficient to guarantee convergence by accepting steps if \eqref{phi-sufficient-progress} is satisfied, in some regimes e.g. when $\schur$ is positive definite, this may select step sizes $\alpha_{P}$ that are too conservative.  For example, this naturally occurs near points satisfying the sufficient conditions for local optimality. In these situation often the KKT error is a better measure of progress towards a local optimum than a merit function that discards information about the dual feasibility. Furthermore, from our experience, when converging towards an optimal solution numerical errors in the function $\phi_{\mu}$ may cause the algorithm to fail to make sufficient progress on the merit function $\phi_{\mu}$ i.e. \eqref{phi-sufficient-progress} is not satisfied for any $\alpha_{P}$. For these reasons we decide to use a filter approach \cite{fletcher2002nonlinear,wachter2006implementation}. Typical filter methods \cite{fletcher2002nonlinear} require progress on either the constraint violation or objective function. Our approach is distinctly different, because we accept steps that make progress on either the merit function $\phi_{\mu}$ or the merit function $\meritKKT_{\mu}$.
% where we accept any step that makes sufficient progress on the function $\phi$ i.e. \eqref{phi-sufficient-progress}  or sufficient progress is made on the KKT merit function relative to historical iterates. 
To be precise we accept any iterate $(x^{+}, y^{+}, s^{+}, \mu^{+})$ that makes sufficient progress on the augment log barrier function $\phi_{\mu}$, or satisfies the following two equations
\begin{subequations}\label{eq:filter}
\begin{flalign}
\meritKKT_{\mu} (x^{+}, y^{+}, s^{+}) &\le (1 - \parKKTReductFactor \alpha_{P} ) \meritKKT_{\mu} (\hat{x}, \hat{y}, \hat{s}) \label{eq:kkt-progress} \\
\phi_{\mu}(x^{+}, y^{+}, s^{+}) &\le \phi_{\mu}(\hat{x}, \hat{y}, \hat{s}) + \sqrt{\meritKKT_{\mu} (\hat{x}, \hat{y}, \hat{s})} % + \meritKKT_{\mu} (\hat{x}, \hat{y}, \hat{s})^2 \right), \alpha_{P}
\end{flalign} %\parFilterReduceBarrier
\end{subequations}
\yinyu{This looks a new idea! (?), a mixed criteria to measure progress.}
 for every previous iterate $(\hat{x}, \hat{y}, \hat{s}, \hat{\vioVar})$ with $a(\hat{x}) + \hat{s} = a(x) + s$.

The idea of \eqref{eq:filter} is that for points with similar values on the augmented log barrier function the KKT error is a good measure of progress. However, we want to discourage the algorithm from significantly increasing the augmented log barrier function while reducing the KKT error. Since, if this is occurring the algorithm might converge to a saddle point. 



\subsubsection{Stabilization step algorithm}

During the backtracking line search we terminate with $\status = \failure$ if:
\begin{flalign}\label{eq:min-step-size-stable}
\alpha_{P} \le \parMinStableStepSize.
\end{flalign}
When this occurs we exit Algorithm~\ref{alg:stable} and go to line~\ref{increase-delta-for-failure} of Algorithm~\ref{one-phase-IPM}. On line~\ref{increase-delta-for-failure} we increases the size of $\delta$ and a new stabilization step is attempted. From Lemma~\ref{coroConsecutiveStable} we know for sufficiently large $\delta$ the stabilization step will succeed.

To ensure that we do not perform unnecessary line searches we only attempt a stabilization line search if the following inequalities holds:
\begin{flalign}
\tilde{\Delta}^{\phi_{\mu}}_{(x,y)}(d_{x}, d_{y}) < 0 \label{eq:obj-could-improve}
\end{flalign}
The idea of this equation is to only take steps when it is possible that $\phi$ can be decreased.
%\delta \| d_{x} \|_{\infty} &\le (1 - \parKKTReductFactor) \max\{ \| \nabla \Lag(x, y ) \|_{\infty}, \| S y - \mu \|_{\infty} \} \label{eq:KKT-could-improve} \\


\begin{algorithm}[H]
\textbf{Input:} The point $(x,y,s, \mu)$, the matrix $\mathcal{K}_{\delta}$ and its factorization $\mathcal{K}_{\delta}^{-1}$. \\ An approximate log barrier hessian $\schur$. \\
\textbf{Output:} A new point $(x^{+}, y^{+}, s^{+}, \mu^{+})$ and a $\status$ of either $\success$ or $\failure$
\begin{enumerate}[label*=A.{\arabic*}]
\item Compute the vector $b$ at the point $(x,y,s, \mu)$ via \eqref{def:b} with $\eta = 0$.
\item Solve the system $\mathcal{K}_{\delta} d = -b$.
\item \emph{Check that the direction has a reasonable chance of being accepted.} If \eqref{eq:obj-could-improve} is not satisfied then terminate with $\status = \failure$.
\item Estimate the largest primal step size $\alpha^{\max}_{P}$ from equation~\eqref{fracBoundaryPrimalMax}.
\item \backtrackBlurb \label{line:sbl-backtrack}
\begin{enumerate}[label=({\roman*})] 
\item The fraction to the boundary rule \eqref{fracBoundary} is satisfied.
\item The set of valid dual step sizes is non-empty i.e. $B( s^{+}, d_{y} ) \neq \emptyset$.
\item \emph{Sufficient progress on filter.} Either equation~\eqref{phi-sufficient-progress} or \eqref{eq:filter} is satisfied.
\end{enumerate}
Terminate with $\status = \failure$ if the step size becomes too small i.e. equation~\eqref{eq:min-step-size-stable} is satisfied.
\end{enumerate}
\caption{High level description of stabilization steps}\label{alg:stable}
\end{algorithm}






\subsection{Algorithm Parameters}

\begin{table}[H]
\begin{tabular}{ |c| p{7cm}|c|c| } 
 \hline
Parameter & Description & Possible values & Chosen value  \\ 
 \hline
$\parNumCor$ & Maximum number of steps per outer iteration. See \eqref{take-steps} of Algorithm~\ref{one-phase-IPM}.  & Any natural number & $3$  \\ 
 \hline
  $\parComp$ & Restricts how far complementarity of $s$ and $y$ can be from $\mu$. See \eqref{satisfy-comp}.  & The interval $(0,1)$ & $0.01$ \\ 
 \hline
   $\parCompAgg$ & Restricts how far complementarity of $s$ and $y$ can be from $\mu$ in order for the aggressive criterion to be met. See \eqref{agg-criteron-buffer}.  & The interval  $(\parComp,1)$ & $0.02$  \\ 
    \hline
   $\parMinStableStepSize$ & Minimum step size for stable line searches. See \eqref{eq:min-step-size-stable}.  & The interval $(0,1)$ & $2^{-5}$  \\ 
   \hline 
      $\parKKTReductFactor$ & Acceptable reduction factor for the scaled KKT error $\meritKKT_{\mu}$ during stabilization steps. See \eqref{eq:kkt-progress}.  & The interval $(0,1)$ & 0.2 \\ 
      \hline
            $\parObjReductFactor$ & Acceptable reduction factor for the merit function $\phi_{\mu}$ during stabilization steps. See \eqref{phi-sufficient-progress}.  & The interval $(0,1)$ & 0.1  \\
    \hline
    $\parBacktracking$ & Backtracking factor for line searches in Algorithm~\ref{alg:aggressive} and \ref{alg:stable}. & The interval $(0,1)$ & 0.5 \\
\hline
 $\parFracBoundary$ & Fraction to the boundary parameter.  & The interval $(0,1)$ & 0.1 \\ 
        \hline
$\parFracBoundaryMax$ & Fraction to the boundary parameter used in \eqref{fracBoundaryPrimalMax} for computing the maximum step size $\alpha_{P}^{\max}$. & The interval $(\parFracBoundary,1)$ & $0.2$ \\
\hline
$\parFracBoundaryExp$ & Exponent of $\| d_{x} \|$ used in fraction to boundary formula \eqref{fracBoundaryPrimalMax} for computing the maximum step size $\alpha_{P}^{\max}$. & The interval $(1,2)$ & 1.5 \\
\hline
$\parRegularizer$ & Used in the regularizer defined in \eqref{def:regularizer}. & The interval $(0,\infty)$ & $10^{-8}$ \\
\hline
$\parConRegularizer$ & Used in the regularizer defined in \eqref{def:regularizer}. & The interval $(0,\infty)$ & $10^{-4}$ \\
\hline
$\parInitialize$  & Used in the initialization & The interval $(0,\infty)$ & ??? \\
\hline
$\parDeltaMin$ &  & The interval $(0,\infty)$ & $10^{-8}$ \\
\hline
$\parDeltaIncreaseFailure$ & &The interval $(1,\infty)$ & $8$ \\
\hline
\end{tabular}
\caption{Parameters values and descriptions}
\end{table}


\section{Theoretical justification}\label{sec:theory}

The goal of this Section provide some simple theoretical justification for our algorithm. Section~\ref{sec:infeas-criteron-justify} justifies infeasibility termination criterion. Section~\ref{sec:theory-naive} provides a simplified version of our algorithm, this is used to explain our algorithms global convergence properties. Section~\ref{sec:global-conv} proves that the algorithm described in Section~\ref{sec:basic-alg} eventually converges. 

\subsection{Derivation of primal infeasibility termination criterion} \label{sec:infeas-criteron-justify}

The purpose of this section is to justify our choice of local infeasibility termination criterion, by showing that it corresponds to stationary measure for the infeasibility with respect to a weighted $L_{\infty}$ norm. We also prove when the problem is convex our criterion certifies global infeasibility.

Consider the following optimization problem:
\begin{subequations}\label{infeasible-problem}
\begin{flalign}
\min_{x} \max_i{ \bar{w}_i a_i(x) }  \\
\text{s.t. } a_i(x) \le 0, \forall i \in \zeroSet
\end{flalign}
\end{subequations}

For some non-negative vector $\bar{w}$ with  $\bar{w}_i = 0$ if and only if $i \in \zeroSet$. For example, a natural choice $\zeroSet$ is the indices of constraints that have been chosen to be satisfied throughout the algorithm i.e. the bound constraints and $\bar{w}_i = 1$ for $i \not\in \zeroSet$. In this case, the problem reduces to
\begin{flalign*}
\min_{x} \max_i{ a_i(x) }  \\
\text{s.t. } a_i(x) \le 0, \forall i \in \zeroSet
\end{flalign*}
Note that \eqref{infeasible-problem} is equivalent to the following optimization problem:
\begin{subequations}\label{feas-problem}
\begin{flalign}
\min \vioVar \\
\text{s.t. } a(x) + s = \vioVar \conWeight \\
s, \vioVar \ge 0,
\end{flalign}
\end{subequations}
where the vector $w$ is defined by $w_i = \bar{w}_i^{-1}$ for $i \not\in \zeroSet$ and $w_i = 0$ for $i \in \zeroSet$. 

The KKT conditions for this problem are:
\begin{flalign*}
a(x) + s = \vioVar \conWeight  \\
\nabla a(x)^T \tilde{y}  = 0 \\
\conWeight^T \tilde{y}  + u = 1 \\
u \vioVar = 0  \\
\tilde{y}^T s = 0 \\
u, \vioVar \ge 0.
\end{flalign*}
Note that if the point $x,y,s, \vioVar$ satisfies:
\begin{flalign*}
a(x) + s = \vioVar \conWeight  \\
\infeasFunc (x,y,s, \vioVar) = 0 \\
\vioVar > 0
\end{flalign*}
then we have found an stationary point problem~\eqref{infeasible-problem} with $\vioVar > 0$. In other words, a first order infeasibility certificate. 

In the case, of convexity a stronger statement can be made. In particular, if the problem is convex, then the stationary point is a global minimizer. The following claim makes this more precise, showing that our termination criterion implies the problem is infeasible in some radius $R$. We emphasize this result is trivial and we include it for completeness.

\begin{claim}
Assume the constraint function $a : \R^{\nvar} \rightarrow \R$ is differentiable and convex. Furthermore, that some minimizer $(x^{*}, \mu^{*})$ of \eqref{feas-problem} satisfies $\| x - x^{*} \|_{2} \le R$ for some constant $R > 0$. Suppose also that at some point $(x,y,s,\mu)$ one has:
\begin{flalign}
a(x) + s &= \vioVar \conWeight \label{eq:assume-primal-good} \\
\infeasFunc (x,y,s, \vioVar) &\le \frac{1}{2 m ( R + 1)}. \label{eq:assume-infeas-criteron-holds}
\end{flalign}
Then the system $a(x) \le 0$ has no feasible solution.
\end{claim}
\begin{proof}
Using $\tilde{y} := \frac{y}{\| Y\conWeight\|_{\infty}}$ we can write:
\begin{flalign*}
\tilde{y}^T a(x^{*}) &\ge \tilde{y}^T a(x) + \tilde{y}^T \nabla a (x) (x^{*} - x) \\
&= \tilde{y}^T (w \mu - s) + \tilde{y}^T \nabla a (x) (x^{*} - x) \\
&\ge \mu - m (1 + R) \infeasFunc (x,y,s, \vioVar) \min\{  1, \vioVar  \} \\
&> \mu/2
\end{flalign*}
The first transition holds via convexity, the second by \eqref{eq:assume-primal-good}, the third by the definition of $\infeasFunc$ and the final inequality by \eqref{eq:assume-infeas-criteron-holds}. Therefore there exists no feasible solution to $a(x) \le 0$. This is a typical Farkas infeasibility certificate argument.
\end{proof}

\subsection{Global convergence proofs for a naive algorithm}\label{sec:theory-naive}

Here we present Algorithm~\ref{alg:naive}, a naive version of Algorithm~\ref{one-phase-IPM}. The goal of this naive algorithm is to illustrate the ideas of the global convergence proof of Algorithm~\ref{one-phase-IPM} (the full proof for Algorithm~\ref{one-phase-IPM} is given in the following section). One should think of Algorithm~\ref{alg:naive} as mimicking the worst case performance of Algorithm~\ref{one-phase-IPM}. However, in practice, Algorithm~\ref{alg:naive} would be much slower than  Algorithm~\ref{one-phase-IPM}. We emphasize that the goal of these convergence proofs is to prove asymptotic convergence to a stationary point, not to give a fast theoretical runtime bound. For work on fast theoretical runtimes for interior point methods with non-convex constraints see [REF OUR PAPER]. 
%\cite{ye1998complexity, bian2015complexity}

\begin{algorithm}[H]
\textbf{Input:} Some point $x^{0}$ and $\mu^{0} > 0$ with $a(x^{0}) < \mu^{0} e$ \\

For $k = 0, ..., \infty$
\begin{enumerate}[label*=A.{\arabic*}]
\item \label{stabilization-stage} \emph{Stabilization stage}. Starting from $x^{k-1}$ find any stationary point to the shifted log barrier problem $\min_{x} \barrier_{\mu^{k}}(x)$ i.e.
$$
x^{k} \in \{ x \in \R^{n} : \nabla \barrier_{\mu^{k}}(x) = 0 \}
$$
%$\barrier_{\mu}(x^{k+1}) \le \barrier_{\mu}(x^{k})$
%starting from the point $x^{k-1}$ find a stationary point $x^{k}$, or show the problem is unbounded from bellow i.e. generate a sequence $\hat{x}^{i}$ such that $\barrier_{\mu^k,\mu^k}(\hat{x}^{i}) \rightarrow -\infty$.
\item \emph{Update dual and slack variables}. Set 
\begin{subequations}
\begin{flalign}
s^{k} &\gets \mu^{k} e - a(x^{k}) \label{naive:stb:s} \\
y^{k} &\gets \mu^{k} (S^{k})^{-1} e. \label{naive:stb:y}
\end{flalign}
\end{subequations}

\item \emph{Check termination criterion}. If \termination{} is satisfied then terminate the algorithm.
\item \label{agg-stage} \emph{Aggressive stage}. Set
\begin{subequations}
\begin{flalign}
\alpha^k_{P} &\gets \frac{1}{2} \min\left\{ 1, \frac{\min_i\{ s_i^{k} \}}{\mu^k} \right\} \label{naive:agg:alpha} \\
\mu^{k+1} &\gets \mu^{k} (1 - \alpha^k_{P} )  \label{naive:agg:mu} \\
\bar{s}^{k} &\gets \mu^{k+1} - a(x^{k})  \label{naive:agg:s} \\
\bar{y}^{k} &\gets \bar{\mu}^{k} (\bar{S}^{k})^{-1} e. \label{naive:agg:y}
\end{flalign}
\end{subequations}
\end{enumerate}
\caption{Naive version of Algorithm~\ref{one-phase-IPM}}\label{alg:naive}
\end{algorithm}

We now describe the similarities between Algorithm~\ref{one-phase-IPM} and Algorithm~\ref{alg:naive}. First note that the sequence:
\begin{flalign}
(x^{k}, s^{k}, y^{k}, \mu^{k})
\end{flalign}
corresponds to the subsequence satisfying the aggressive step criterion \eqref{agg-criteron} in Algorithm~\ref{one-phase-IPM}. Furthermore, the sequence
\begin{flalign}\label{eq:worst-case-agg-sequence}
(x^{k}, \bar{s}^{k}, \bar{y}^{k}, \mu^{k+1})
\end{flalign}
corresponding to the subsequence of iterates generated by Algorithm~\ref{alg:aggressive} i.e. aggressive steps.

In Algorithm~\ref{one-phase-IPM}, the stabilization step is repeatedly called until the aggressive step criterion~\eqref{agg-criteron} is met. This series of consecutive stabilization steps can be viewed as equivalent one call to the stabilization stage in Algorithm~\ref{alg:naive}. Now, during an aggressive step in Algorithm~\ref{one-phase-IPM}, if we let $\delta \rightarrow \infty$ then $x^{+} \rightarrow x$. Hence \eqref{eq:worst-case-agg-sequence} can be thought of as the `worst case' aggressive sequence, corresponding to huge choice of $\delta$. Now,
% the primal variable updates \eqref{eq:xVarUpdate} and \eqref{eq:slackVarUpdate} reduce to $s^{+} \gets s - \alpha_{P} e$ and $x^{+} \gets x$ which is roughly equivalent to the aggressive stage of Algorithm~\ref{alg:naive} since:
\begin{flalign}
\bar{s}^{k} = \mu^{k+1} e - a(x^{k}) = \mu^{k+1} e - (\mu^{k} e - s^{k} )  = s^{k} - \mu^{k} \alpha^k_{P} \ge s^k / 2 > 0%\label{eq:bar-s-k}
\end{flalign}
where the first equality follows by \eqref{naive:agg:s}, second by \eqref{naive:stb:s}, the third by \eqref{naive:agg:mu}, and the first inequality from \eqref{naive:agg:alpha}. Hence each point $x^{k}$ satisfies $\mu^{k+1} e - a(x^{k}) > 0$ and is therefore a strictly feasible starting point to the shifted log barrier problem 
$\barrier_{\mu^{k+1}}(x)$ defined in line~\ref{stabilization-stage} of Algorithm~\ref{alg:naive}. 

For simplicity of exposition, in Algorithm~\ref{alg:naive}, we assume that we have some oracle that will find a stationary point of the sub-problem $\min_{x} \barrier_{\mu^k}(x)$ given an initial point $x^{k}$. Most descent algorithms for unconstrained optimization will achieve this, assuming $f$ and $a$ are continuously differentiable. We show the convergence of the stabilization steps for this solving these sub-problems in Section~\ref{sec:global-conv}. 

In Theorem~\ref{thm:naive} we show this naive algorithm (Algorithm~\ref{alg:naive}) eventually terminates. Here we sketch the proof. Assume, that at each $x^{k}$ the first order local infeasibility is not satisfied (since otherwise the algorithm trivially terminates). A consequence of this assumption is that the dual variables are bounded from above. Since the dual variables are bounded above, we can bound the slack variables away from zero. By applying the update formula for $\mu^{k}$ given in \eqref{naive:agg:mu} we conclude $\mu^{k}$ is reduced sufficiently at each iteration and therefore $\mu^{k} \rightarrow 0$. Finally, observe that the iterates of Algorithm~\ref{alg:naive} satisfy
\begin{subequations}
\begin{flalign}
a(x^{k}) + s^{k} &= e \mu^k \\
\nabla_{x} \Lag(x^{k}, y^{k}) &= 0 \\
S^{k} y^{k} &= \mu^k e \\
s^{k}, y^{k} &\ge 0,
\end{flalign}
\end{subequations}
hence the central sequence property defined in equations \eqref{eq:barrier-primal-sequence-nice} and \eqref{eq:dual-feas} holds. Hence, since $\mu^k \rightarrow 0$ eventually the optimality criterion is satisfied.

\begin{theorem}\label{thm:naive}
Assume that: 
\begin{enumerate}
\item The functions $f : \R^{\nvar} \rightarrow \R$ and $a : \R^{\nvar} \rightarrow \R^{\ncon}$ are differentiable on $\R^{\nvar}$.
\item The input parameters satisfy $\TOLopt \in (0, \min\{ \mu^{0}, 1 \} ]$. %, \TOLinf, \TOLunbounded
\item The level sets of the function $\barrier_{\mu}(x)$ are bounded for all $\mu \le \mu^{0}$.
\item There exists some constant $\maxgrad \ge \max\{ \mu^{0}, \| \nabla f(x) \|_{\infty} \}$ for all $x \in \R^{\nvar}$ .
\end{enumerate}
Then at any iteration $k$ where the infeasibility termination criterion~\eqref{terminate-primal-infeasible} is not satisfied,
$$
\| y^{k} \|_{\infty} \le \frac{2 G}{ \TOLinf \TOLopt}.
$$
Furthermore, either Algorithm~\ref{alg:naive} terminates in at most 
$$
1 + \frac{4 \maxgrad}{\TOLopt \TOLinf } \log\left( \frac{\mu^{0}}{\TOLopt} \right)
$$
iterations.
\end{theorem}

\begin{proof}
By the assumption that the level sets of $\barrier_{\mu^k}(x)$ are bounded and the existence of a feasible solution $x^{k}$, we can deduce the set $\arg \min_{x} \barrier_{\mu^{k}}(x)$ is non-empty.
Since $\arg \min_{x} \barrier_{\mu^{k}}(x) \subseteq \{ x \in \R^{n} : \nabla \barrier_{\mu^{k}}(x) = 0 \}$ it follows that $\{ x \in \R^{n} : \nabla \barrier_{\mu^{k}}(x) = 0 \}$ is non-empty. We conclude that 
the stabilization stage (line~\ref{stabilization-stage}) of Algorithm~\ref{alg:naive} is well-defined.

Next, we have
\begin{flalign*}
\| y^{k} \|_{\infty} &\le \frac{\| \nabla a(x^k)^T y^k \|_{\infty} + \| Y^k s^k \|_{\infty}}{ \TOLinf \min\{  1, \mu^k \}} \\
& \le  \frac{\| \nabla f(x^{k}) \|_{\infty} + \mu^{k}}{ \TOLinf \min\{  1, \mu^{k} \}} \\
& \le \frac{2 G}{ \TOLinf \TOLopt} 
\end{flalign*}
where the first inequality follows from the fact that the \eqref{terminate-primal-infeasible} is not satisfied; the second inequality from $\| \nabla \Lag (x^k , y^k) \|_{\infty} = 0$ and $S^k y^k = \mu^k$. The third inequality from the assumptions that $G \ge \mu^{k}$ and $\TOLopt \le 1$.
Now,
\begin{flalign*}
\mu^{k+1} &\le \mu^k  - (1/2) \min_{i}{s_{i}^{k} } \\
&= \mu^k \left( 1 - \frac{1}{2 \| y^{k} \|_{\infty}} \right) \\
&\le \mu^{k} \left(1 - \frac{\TOLopt \TOLinf }{4 \maxgrad} \right) \\
&\le \mu^{k} \exp\left( - \frac{\TOLopt \TOLinf }{4 \maxgrad}  \right).
\end{flalign*}
where the second transition holds from $S^k y^{k} = \mu^k e$, the third transition by our bound on $\| y^k \|_{\infty}$ and the fourth transition since $\frac{\TOLopt \TOLinf }{4 \maxgrad} < 1$. 
%We conclude that $\mu^{k} \le \mu^{0} \exp\left( - k \frac{\TOLopt \TOLinf }{4 \maxgrad}  \right)$$
Noting that $\mu^k \le \TOLopt$ implies the algorithm terminates, gives the result. 
\end{proof}

Comparing the assumptions of Theorem~\ref{thm:naive} and (the convergence proof for Algorithm~\ref{one-phase-IPM}) Theorem~\ref{thm:global-convergence}, we notice that Theorem~\ref{thm:naive} uses stronger assumptions. The goal is to simplify the exposition. Keep in mind that Theorem~\ref{thm:naive} only bounds the number of iterations and excludes the computational cost of each solve of the stabilization stage.

\subsection{Global convergence proofs for Algorithm~\ref{one-phase-IPM}}\label{sec:global-conv}

We now give a global convergence proof for Algorithm~\ref{one-phase-IPM} as stated in Theorem~\ref{thm:global-convergence}. We remark that the proof is mostly mechanical, for this reason we place most of it in Appendix~\ref{app:global-conv}. 
%however, we have included it to clearly demonstrate that our algorithm converges. 

%The majority of this section will be in the appendix for the real paper. The main result is Theorem~\ref{thm:global-convergence} which shows global convergence of Algorithm~\ref{one-phase-IPM} to a point satisfying the termination criterion. 

\hinder{twice differentiable on domain $a(x) \le \mu^0 \conWeight$}

\subsubsection{Convergence of aggressive steps}

The goal of this section is show that after a finite number of calls to aggressive steps Algorithm~\ref{one-phase-IPM} converges. Lemma~\ref{lem:agg-finite} and Lemma~\ref{lemma:agg-succeeds} use similar proof ideas to Theorem~\ref{thm:naive}. In particular, Lemma~\ref{lem:agg-finite} uses the infeasibility termination criterion~\eqref{terminate-primal-infeasible} to bound the dual variables and uses that to show successful aggressive steps will converge. Lemma~\ref{lemma:agg-succeeds} uses the fact that for large enough $\delta$ the slack variables can be used to reduce the barrier parameter $\mu$.


\begin{restatable}{lemma}{lemAggFinite}\label{lem:agg-finite}
Assume that:
\begin{enumerate}
\item The functions $f : \R^{\nvar} \rightarrow \R$ and $a : \R^{\nvar} \rightarrow \R^{\ncon}$ are twice differentiable. 
\item There exists some constant $G \ge \max\{ \mu^{0} / \parComp, \| \nabla f(x) \|  \}$ for all $x \in \R^{\nvar}$. 
\item The tolerance $\TOLopt \in (0,1)$.
\end{enumerate}
Consider a point $(x, y, s, \mu)$ that satisfies the criterion for an aggressive step \eqref{agg-criteron}, but does not satisfy the infeasibility termination criterion~\eqref{terminate-primal-infeasible} then:
$$
\| Y \conWeight \|_{\infty} \le \frac{2 G}{\TOLinf \TOLopt}
$$
Furthermore, after a finite number of calls to Algorithm~\ref{alg:aggressive} that terminate with $\status = \success$, Algorithm~\ref{one-phase-IPM} will terminate at a point $(x, y, s, \mu)$ satisfying the local optimality termination criterion \eqref{terminate-kkt}. 
\end{restatable}

The proof of Lemma~\ref{lem:agg-finite} is given in Section~\ref{sub:lem:agg-finite}. Note Lemma~\ref{lem:agg-finite} does not rule out the possibility of an infinite sequence of failing aggressive steps. For this reason we need Lemma~\ref{lemma:agg-succeeds}. Lemma~\ref{lemma:agg-succeeds} shows that one can absorb the slack variable to reduce $\mu$ during aggressive steps by choosing a sufficiently large $\delta$. Consequently, we are guaranteed if the criterion for an aggressive step is satisfied then there will be eventually an aggressive step taken with $\status = \success$ (since when an aggressive step fails for $j=1$ the parameter $\delta$ is increased inside Algorithm~\ref{one-phase-IPM} and eventually $\delta > \bar{\delta}$).

\begin{restatable}{lemma}{lemAggSucceeds}\label{lemma:agg-succeeds}
Let the functions $f : \R^{\nvar} \rightarrow \R$ and $a : \R^{\nvar} \rightarrow \R^{\ncon}$ be twice differentiable. Consider an iterate $(x, y, s, \mu)$ that satisfies the criterion for an aggressive step \eqref{agg-criteron} with $a(x) + s = \vioVar \conWeight$, then there exists some $\bar{\delta}$ such that for all $\delta > \bar{\delta}$, Algorithm~\ref{alg:aggressive} applied to the iterate $(x, y, s, \mu)$ terminates with $\status = \success$.
\end{restatable}

The proof of Lemma~\ref{sec:lemma:agg-succeeds} is given in Section~\ref{sec:lemma:agg-succeeds}. We conclude this subsection with Lemma~\ref{lem:summary-agg}, that summarizes the important aspects of Lemma~\ref{lem:agg-finite} and Lemma~\ref{lemma:agg-succeeds}.

\begin{lemma}\label{lem:summary-agg}
Let the functions $f : \R^{\nvar} \rightarrow \R$ and $a : \R^{\nvar} \rightarrow \R^{\ncon}$ be twice differentiable.
After a finite number of calls to Algorithm~\ref{alg:aggressive}, Algorithm~\ref{one-phase-IPM} terminates.
%After a finite amount of computational time after the aggressive criterion~\eqref{agg-criteron} is met a successful aggressive step is taken and Algorithm~\ref{one-phase-IPM} terminates after a finite number of aggressive steps.
\end{lemma}

However, Lemma~\ref{lem:summary-agg} does not rule out the possibility there is an infinite number of consecutive stabilization steps. Ruling out this possibility is the purpose of subsection~\ref{conv:stb}.

\subsubsection{Convergence of stabilization steps}\label{conv:stb}

This subsection is devoted to showing that consecutive stabilization steps eventually satisfy the criterion for an aggressive step or the unboundedness criterion is satisfied. We now introduce the set $\mathbb{Q}_{\mu, C}$ which we will use to represent the set of possible points the iterates of Algorithm~\ref{one-phase-IPM} can take for a fixed $\mu$ i.e. during consecutive stabilization steps.

\begin{definition}
Define the set $\mathbb{Q}_{\mu, C}$ for constants $\mu, C > 0$ as the set of points $(x,y,s) \in  \R^{\nvar} \times \R^{\ncon++} \times \R^{\ncon++}$ such that
\begin{enumerate}
\item The function $\phi_{\mu}$ is bounded above i.e. $\phi_{\mu}(x,y,s) \le C$.
\item The unboundedness termination criterion~\eqref{terminate-dual-infeasible} is not satisfied i.e.
\begin{flalign*}
\frac{ \|\max\{ a(x), e \} \|_{\infty}  }{\max\{1,-f(x) \} } \ge \TOLunbounded. 
\end{flalign*} \hinder{does this match the termination criterion??}
\item The dual and slack variables are strictly positive i.e $y, s > 0$. Furthermore, equation~\eqref{eq:primal-feasibility} and \eqref{eq:comp-slack} are satisfied:
\begin{flalign*}
a(x) + s &= \mu \conWeight \\
\frac{S y}{\mu} &\in [\parComp e, e / \parComp]
\end{flalign*} 
\end{enumerate}
\end{definition}

Hence if Algorithm~\ref{one-phase-IPM} generates consecutive stabilization steps $(x^{k}, s^{k}, y^{k}, \mu^k)$ starting at the point $(x^{1}, s^{1}, y^{1},  \mu^{1})$ with $\mu^{1} = \mu^{k}$. Then we know that if we set $C = \phi_{\mu^{1}}(x^{1}, s^{1}, y^{1})$ then all these consecutive stabilization steps are contained in $\mathbb{Q}_{\mu, C}$ i.e. $(x^{k}, s^{k}, y^{k}) \in \mathbb{Q}_{\mu, C}$. 

%With the definition of $\mathbb{Q}_{\mu, C}$ in hand, we state Lemma~\ref{lem:compact-Q}.  \hinder{this lemma is a consequence of the regularizer choice}

\begin{restatable}{lemma}{lemCompactQ}\label{lem:compact-Q}
Let the functions $f : \R^{\nvar} \rightarrow \R$ and $a : \R^{\nvar} \rightarrow \R^{\ncon}$ be continuous. For any constants $\mu > 0$ and $C \in \R$, the set $\mathbb{Q}_{\mu, C}$ is compact.
\end{restatable}

The proof of Lemma~\ref{lem:compact-Q} is given in Section~\ref{sec:lem:compact-Q}. We give a quick explanation here. Firstly, if we converge towards a point on the boundary of the feasible region the value of $\phi_{C}$ goes towards infinity, this cannot occur since $\phi_{C}(x, y, s) \le C$. Similarly, if the norm of the primal variables tends towards infinity while $\phi_{C}(x, y, s) \le C$, then the regularizer $r$ will make the objective function go towards negative infinity and therefore the objective is unbounded from bellow.

\begin{restatable}{corollary}{coroConsecutiveStable}\label{coroConsecutiveStable}
Let the functions $f : \R^{\nvar} \rightarrow \R$ and $a : \R^{\nvar} \rightarrow \R^{\ncon}$ be twice differentiable.
After a finite number of consecutive stabilization steps either the aggressive criterion~\eqref{agg-criteron} or the unboundedness termination criterion~\eqref{terminate-dual-infeasible}  is met.
\end{restatable}

The proof of Corollary~\ref{coroConsecutiveStable} is given in Section~\ref{sec:coroConsecutiveStable}. Let us sketch the main ideas. Recall that a continuous function on a compact set has a supremum. Consequently, Lemma~\ref{lem:compact-Q} allows us to uniformly bound quantities such as Lipschitz constants. The crux of the proof is showing if there is an infinite number of consecutive stabilizations steps there will either be an infinite sequence of iterations that either reduce the augmented log barrier merit function or the KKT error. Since the KKT error is bounded bellow, the only remaining possibility is that we indefinitely reduce the augmented log barrier merit function. This implies the unboundedness termination criterion holds and therefore 
%Since both the augmented log barrier function and KKT error are bounded bellow contradiction

We now state Theorem~\ref{thm:global-convergence}, the main theoretical result of the paper.

\begin{theorem}\label{thm:global-convergence}
Let the functions $f : \R^{\nvar} \rightarrow \R$ and $a : \R^{\nvar} \rightarrow \R^{\ncon}$ be twice differentiable.
Algorithm~\ref{one-phase-IPM} terminates after a finite number of computational operations.
\end{theorem}

\begin{proof}
Lemma~\ref{lem:summary-agg} show that the algorithm must terminate after a finite number of aggressive steps and each aggressive step occurs in a finite number of computational operations.
Corollary~\ref{coroConsecutiveStable} shows that the algorithm terminates or an aggressive step must be taken after a finite number of stabilization steps. The result follows.
\end{proof}


\hinder{nice thing about global convergence proofs -- they enable debugging of the algorithm i.e. what is a numerical error and what is due to algorithm design}

\section{Implementation details}\label{sec:implementation-details}


\subsection{Initialization}\label{sec:initialization}


This section explains how given a starting point $x_{\text{start}}$, how to select the initial variable values $(x^0, y^0, s^0, \mu^0)$ before calling Algorithm~\ref{one-phase-IPM}.

The first goal is to modify the starting point such that it satisfies any bounds on the variables e.g. $l \le x \le u$. Let $\mathcal{B} \subseteq \{ 1, \dots, \ncon \}$ be the set of constraints indices corresponding to bound constraints. More precisely, $i \in \mathcal{B}$ if and only if there exists $c \in \R$ such that $a_i(x) = e_j^T x + c$ or $a_i(x) = -e_j^T x + c$. We project onto the variable bounds in the same way as IPOPT \cite[Section 3.7]{wachter2006implementation}. Furthermore, we set $w_i = 0$ and $s_i^{0} = -a_i(x^0)$ for each $i \in \mathcal{B}$. This ensures that the variable bounds are satisfied throughout the algorithm, and is useful because often the constraints or objective may not be defined outside the bound constraints. Note that in general to guarantee that any constraint $a_i(x)$ that was strictly feasible at the initial point $x^{0}$ remains feasible throughout the algorithm we could simply set $\conWeight_i = 0$ and $s_i^{0} = -a_i(x^0)$.
 

%This is done because often the non-linear constraints or objective may not be defined outside the bound constraints. 

%Note that the way we present our work the variables bound correspond to constraints indicies 
%are a subset of the set constraints given by $a_i(x) \le 0$ for $i = 1, ..., m$. We project onto the bounds in the same way as \cite[Section 3.7]{wachter2006implementation}. Note that by setting $a_i(x)

%\begin{flalign}
%x_{i}^{0} \gets \min \{ x_{i}^{0}, u_i \} \\
%x_{i}^{0} \gets \max \{ x_{i}^{0}, l_i \} 
%\end{flalign}
%where $l$ and $u$ correspond to the upper and lower bounds defined by the constraints $a$.

%Recall that to start the algorithm, we must select points vector $w \ge 0$, slack variables $s > 0$ and initial barrier parameter $\mu^{0}$ such that
%$$
%a(x^{0}) + s^{0} = w \mu^{0}
%$$
%How do we choose these variables? Suppose that the initial point is given to us (otherwise set $x_0$).
%we some initial primal and dual variables $x^{0}$ and $\bar{y}^{0} > 0$
The remainder of the initialization scheme is inspired by Mehrotra's work for linear programming \cite{mehrotra1992implementation}, but has been adapted to the non-linear programming context. We select a candidate dual variable and slack variables as follows 
\begin{flalign*}
\tilde{y} &\gets \nabla a(x^0) (\nabla a(x^0)^T \nabla a(x^0) + I \parInitialize)^{-1}  \nabla f(x^0) \\
\tilde{s} &\gets -a(x^{0})
\end{flalign*}
\hinder{check this matches!!!}
for some parameter $\parInitialize \in (0,\infty)$.

Consider the following scalar variables:
\begin{flalign}
& \varepsilon_{y} \gets \max\{ -2 \min_i{ \tilde{y}_i}, 0 \}  \\
& \varepsilon_{s} \gets \max\left\{ - 2 \min_i{ \tilde{s}_i}, \frac{\| \nabla \Lag(x^{0}, \tilde{y}) \|_{\infty}}{\| \tilde{y} \|_{\infty} + 1} \right\} %\frac{\tilde{s}^T y }{\| y \|_{1}} +
\end{flalign}
then set:
\begin{flalign}
y^{0} &\gets \tilde{y} + \varepsilon_{y} \\
s^{0} &\gets \tilde{s} + \varepsilon_{s} \\
\mu^{0} &\gets \frac{(s^0)^T y^{0}}{\ncon}
\end{flalign}
Finally, we project $\mu^{0}$ onto the interval  $\| s^{0} \|_{\infty} [10^{-2},10^{5}]$ and project the dual variables $y^{0}$ onto the interval $\mu S^{-1} e [\parComp, 1/\parComp]$.


%The default value is $\kappa = 10^{-3}$.

%\begin{enumerate}
%\item Dealing with bound constraints
%\end{enumerate}
%
%For simplicity consider the case that $\conWeight = e$, observe that for any initial starting point $x^{1}$ we can select the slack variables $s^{1}$ and infeasibility measure $\vioVar^{1}$ via
%\begin{flalign*}
%\vioVar^{1} &\gets 2 \max_i{ -a_i(x^{1}) } \\
%s^{1} &\gets \vioVar^{1} e - a(x^{1}) 
%\end{flalign*}   
\subsection{Linear algebra}\label{sec:linear-algebra}

\todo[inline]{explain how equality and lower/upper bounds can be handled}

\begin{enumerate}
\item Splitting dense columns in sparse linear systems. Linear Algebra and its Applications. Robert J. Vanderbei. \cite{vanderbei1991splitting}
\item \cite{lustig1991formulating} Get between 5 times and 80 times speed up from splitting dense columns for stochastic programs.
\item Matrix Stretching for Sparse Least Squares \url{https://pdfs.semanticscholar.org/0054/9cc96c29f24c9d55d76962676fe5993f2b11.pdf}
\item Matrix Stretching for Linear Equations \url{https://arxiv.org/abs/1203.2377}
\item J. F. Grcar, Matrix stretching for linear equations, Tech. Report SAND90-8723, Sandia
National Laboratories, Nov. 1990.
\end{enumerate}

\subsection{Iterative refinement}

\section{Empirical results}\label{sec:empirical-results}

% and (ii) the NETLIB linear programming
For the empirical results we use the CUTEst non-linear programming test sets. The empirical results are structured as follows. Section~\ref{alg:comparison-options} explores different algorithm options on CUTEst.  Section~\ref{alg:comparison-IPOPT} compares our algorithm against IPOPT on CUTEst. Section~\ref{sec:infeas} compares our algorithm and IPOPT on a set of infeasible problems constructed from CUTEst. %Section~\ref{sec:netlib} compares our algorithm and IPOPT on the NETLIB linear programming test set.

For the comparisons we use IPOPT version 3.12.4 with the linear solver mumps. We turn off the nlp scaling, set the termination tolerance to $10^{-6}$, set the boundary relaxation factor to zero. For both the one phase algorithm and IPOPT we set the time limit to 1 hour and the maximum number of iterations $3,000$.

We selected a subset from the CUTEst test set of with more than $100$ variables and constraints, but the total number of variables and constraints less than $10,000$. We further restricted the CUTEst problems to ones that are classified as having first and second derivatives defined everywhere (and available analytically). This gave us a test set with $238$ problems.

We do not currently compare the number of function value evaluations, but in general we find that IPOPT performs slightly less function evaluations per iteration. However, we feel that for problems where function evaluations are expensive relative to factorization, one is better off using SQP methods rather than interior point methods. For example, it is known that SNOPT generally require less function evaluations than IPOPT \cite[Figure 2, Figure 3]{gill2015performance}.

\subsection{Comparison of different algorithm options}\label{alg:comparison-options}

Comparing algorithms in the following sections we use the performance profiling of \cite{dolan2002benchmarking}.


%\begin{figure}[H]
%\includegraphics[scale=0.5]{ratios-dynamic-static.png}
%\caption{Comparison of dynamic and static $\mu$ updates for the one phase algorithm.}
%\end{figure}

In Figure~\ref{fig:ls-options} we trial different line search conditions for the stabilization steps. In particular, we compare the default setting of a `filter' as described in line~\eqref{line:sbl-backtrack} part (iii) of Algorithm~\ref{alg:stable} against other possible conditions. The first baseline to replace condition (iii) with  \eqref{phi-sufficient-progress} i.e. check that sufficient progress is made on the `log barrier' merit function. The other baseline is removing condition (iii) entirely and simple taking the maximum step possible. Figure~\ref{fig:ls-options} indicates that the filter has superior performance of these three options.

\begin{figure}[H]
\includegraphics[scale=0.5]{ls-options.pdf}
\caption{Comparison of different line search options.}\label{fig:ls-options}
\end{figure}

In Figure~\ref{fig:num-corrections} we compare different choices of the parameter $c_{\max}$, the maximum number of corrections ($c_{\max}$ is used on line~\ref{take-steps} in Algorithm~\ref{one-phase-IPM}). As one would expect, increasing the number of corrections decreases the iteration count, but has little impact on the failure rate. In the actual implementation of our one phase algorithm we chose $c_{\max}=3$.
%can see the number of iterations is

\begin{figure}[H]
\includegraphics[scale=0.5]{num-corrections.pdf}
\caption{Comparison of the maximum number of corrections for the one phase algorithm.}\label{fig:num-corrections}
\end{figure}


\begin{figure}[H]
\includegraphics[scale=0.5]{regularizer-ratios.pdf}
\caption{Comparison of the algorithm with and without the regularizer.}\label{fig:num-corrections}
\end{figure}


\subsection{Comparison with IPOPT}\label{alg:comparison-IPOPT}

Please take these results with a grain of salt since we are comparing iteration counts not runtimes.

\todo[inline]{Comparison on number of function/constraint evaluations (clearly admit algorithm is not optimized to minimize constraint violation/function evaluation)}


We consider the final function values $f^{a}_{*}$ and $f^{b}_{*}$ of algorithm $a$ and $b$ respectively approximately the same if:
$$
\frac{f^{a}_{*} - f^{b}_{*}}{1 + \max \{ | f^{a}_{*} |, | f^{b}_{*} | \} } < 10^{-1},
$$
otherwise, we consider the solution of algorithm $a$ better than algorithm $b$ if $f^{a}_{*}  < f^{b}_{*}$. For problems where both algorithm find a KKT point this is reported in the top three rows of Table~\ref{tbl:pairwise-outcomes}. The remainder of Table~\ref{tbl:pairwise-outcomes} shows the number of times both algorithms succeed, fail, or just one algorithm fails. We consider the algorithm to have succeeded if it produces either a certificate of first order local optimality, infeasibility or unboundedness. 

Let us highlight a few interesting facts from the tables. The one phase algorithm seem to find better KKT points on $13$ problems versus $2$ for IPOPT (Table~\ref{tbl:pairwise-outcomes}). Furthermore, IPOPT fails on $39$ problems compared with $21$ problems for the one phase algorithm (Table~\ref{tbl:termination-status-counts}). A large proportion of these failures occur before IPOPT has started (Table~\ref{tbl:failure-reasons}).

\begin{table}[H]
\caption{Pairwise comparison of outcomes for IPOPT and the one phase algorithm}\label{tbl:pairwise-outcomes}
\begin{tabular}{ c c r }
  One Phase &  IPOPT &  \# \\
  \hline
same KKT & - & 158  \\
- & better KKT & 2 \\
better KKT & - &  13 \\
\hline
Succeed & Succeed & 185 \\
Fails & Fails & 7 \\
Succeed & Fails &  32 \\
Fails & Succeed & 14 \\
\end{tabular}
\end{table}

%Table~\ref{tbl:termination-status-counts} displays the 

\begin{table}[H]
\caption{Termination status counts}\label{tbl:termination-status-counts}
\begin{tabular}{ c c c r }
 &  One Phase &  IPOPT &  \\
  \hline
KKT &  201 & 191 \\
unbounded & 4 & 0  \\
primal infeasible & 12 &  8 \\
fail & 21 & 39 \\
\end{tabular}
\end{table}

\begin{table}[H]
\caption{Failure reasons}\label{tbl:failure-reasons}
\begin{tabular}{ c c c r }
 &  One Phase & IPOPT \\
  \hline
max time & 10 & 9  \\
max iter &  3 & 3 \\
error before starting & 4 & 19 \\
error during algorithm & 4 & 8 \\
\hline
total & 21 & 39
\end{tabular}
\end{table}

Figure~\ref{fig:comparison-IPOPT-on-CUTEst} compares the iterations that IPOPT and the one phase algorithm take to succeed (produce a certificate of first order local optimality, infeasibility or unboundedness) on the CUTEst test set. Note that the iteration counts for the solvers are similar, except that the one phase solver fails less frequently.


\begin{figure}[H]
\includegraphics[scale=0.5]{ratios-IPOPT-one-phase.pdf}
\includegraphics[scale=0.5]{iterations-IPOPT-one-phase.pdf}
%\includegraphics[scale=0.5]{ratios-n=50-10000.png}
%\includegraphics[scale=0.5]{iterations-n=50-10000.png}
\caption{Comparison of IPOPT and one phase on CUTEst for problems where at least one solver declared the problem optimal, infeasible or unbounded.}\label{fig:comparison-IPOPT-on-CUTEst}
\end{figure}

\todo[inline]{table or plot of maximum dual variables? this would significantly strengthen case.}

\subsection{Comparison on infeasible problems}\label{sec:infeas}

Most of the CUTEst problems have feasible solutions. To generate a test set that was more likely to contain infeasible problems we perturbed the constraints as follows:
$$
\tilde{a}(x) = a(x) + e
$$
The solver terminated with the statuses described in the Table~\ref{tbl:termination-status-counts-peturbed}. This test was only run on problems with at most $1,000$ variables and constraints total.
\begin{table}[H]
\caption{Termination status counts for perturbed CUTEst problems.}\label{tbl:termination-status-counts-peturbed}
\begin{tabular}{ c c c r }
 &  One Phase &  IPOPT &  \\
  \hline
KKT & 22 & 20 \\
unbounded & 1 & 0  \\
primal infeasible & 44 &  38 \\
fail & 3 & 12 \\
\end{tabular}
\end{table}

Next, in Figure~\ref{fig:comparison-IPOPT-on-perturbed-CUTEst} we compare IPOPT and the one phase on the subset problems which at least one solver declared the problem locally infeasible. From this figure one can see that the one phase solver is quicker and more robust than IPOPT.

\begin{figure}[H]
\includegraphics[scale=0.5]{infeas-ratios.png}
\caption{Comparison of IPOPT and one phase on perturbed CUTEst problems for which at least one solver declares the problem locally infeasible.}\label{fig:comparison-IPOPT-on-perturbed-CUTEst}
\end{figure}

%
%\subsection{Comparison on NETLIB for linear programming}\label{sec:netlib}
%
%The purpose of this Section is to show that the one phase algorithm has good performance on linear programs, as one would expect since the algorithm is heavily influenced by ideas from linear programming [REF]. My experience from our previous paper is that there is a huge difference in the performance of IPOPT and the one phase algorithm.
%
%[Use IPOPT option specialized for LP]
%
%\begin{figure}[H]
%\missingfigure{...}
%%\includegraphics[scale=0.5]{ratios-n=50-10000.png}
%%\includegraphics[scale=0.5]{iterations-n=50-10000.png}
%\caption{Comparison of IPOPT and one phase on the NETLIB linear programming test set.}
%\end{figure}


\section{Conclusions}
\begin{enumerate}
\item ??
\end{enumerate}


\section{To do}

\begin{enumerate}
\item clean up 
\item edit code to match document
\item run full CUTEst test
\item explain performance on Watcher-Beliger example.
\end{enumerate}

\bibliographystyle{abbrv}
\bibliography{library-one-phase-2.bib}


\appendix

\section{Global convergence proofs for Algorithm~\ref{one-phase-IPM}}\label{app:global-conv}

\subsection{Convergence of aggressive steps}

\subsubsection{Proof of Lemma~\ref{lem:agg-finite}}\label{sub:lem:agg-finite}

\lemAggFinite*

\begin{proof}
We have
\begin{flalign*}
\| Y \conWeight \|_{\infty} &\le \frac{\max\{ \| \nabla a(x)^T y \|_{\infty}, \| S y \|_{\infty} \}}{ \TOLinf \min\{  1, \vioVar \}} \\
& \le  \frac{\max\{\| \nabla f(x) \|_{\infty} + \| \nabla \Lag (x , y) \|_{\infty}, \mu / \parComp \}}{ \TOLinf \min\{  1, \vioVar \}} \\
& \le \frac{ 2 G }{ \TOLinf \TOLopt} 
\end{flalign*}
where the first inequality follows from the fact that the \eqref{terminate-primal-infeasible} is not satisfied; the second inequality from the triangle inequality applied to $\| \nabla \Lag (x , y) \|_{\infty}$ and inequality \eqref{agg-criteron-buffer}; and the third inequality from inequality \eqref{agg-criteron-farkas} and the Lemma's assumptions.

Next, for any trial step size $\alpha_{P}$ by \eqref{min-step-size-aggresssive} we have
\begin{flalign*}
\alpha_{P} &\ge  \min_{i : w_i > 0}{ \frac{\parBacktracking \theta s_{i}}{2 \vioVar \conWeight_i} }
\ge \min_{i : w_i > 0}{ \frac{ \parBacktracking \theta \parCompAgg}{2 \conWeight_i  y_{i}}  } 
\ge \frac{ \parBacktracking \theta \parCompAgg \TOLinf \TOLopt}{4 G}
\end{flalign*}
where the first inequality is from the minimum trial step size from \eqref{min-step-size-aggresssive}, the second inequality from \eqref{agg-criteron-buffer} and the final inequality from our bound on $\| Y\conWeight\|_{\infty}$.

Therefore we reduce $\mu$ by at least $\alpha_{P} \mu$ each call to Algorithm~\ref{alg:aggressive} that terminates with $\status = \success$. Furthermore,  for sufficiently small $\mu$ whenever \eqref{agg-criteron} holds the optimality criterion \eqref{terminate-kkt} is satisfied. Combining these facts proves the Lemma.
\end{proof}

\subsubsection{Proof of Lemma~\ref{lemma:agg-succeeds}}\label{sec:lemma:agg-succeeds}

\lemAggSucceeds*

\begin{proof}
First, observe that as $\delta \rightarrow \infty$ the direction $d_{x}$ computed from \eqref{eq:schur-complement} tends to zero. Consider any $\alpha_{P} \in (0,1)$, since the function $a$ is continuous for sufficiently large $\delta$ we have
\begin{flalign}\label{eq:a-bound}
\| a(x) - a(x + \alpha_{P} d_{x}) \|_{\infty} \le \frac{\theta}{2} \min\{ s_{i} \}
\end{flalign}
where $\theta$ is defined in equation~\eqref{min-step-size-aggresssive}.

To obtain a contradiction assume that Algorithm~\ref{alg:aggressive} fails. This implies by \eqref{min-step-size-aggresssive} that the backtracking line search of the algorithm will have attempted some $\alpha_{P}$ such that
\begin{flalign}\label{eq:alpha-bound}
\alpha_{P} \in \left[ 0, \min_{i : w_i > 0}{ \frac{\theta s_{i}}{2 \vioVar \conWeight_i} }  \right], %\frac{1}{1 + (\vioVar / (  \parCompAgg \mu) ) \| y \|_{\infty}}\right]
\end{flalign}
then for this choice of $\alpha_{P}$ we have
$$
\| s^{+} - s \|_{\infty} = \|  -\alpha_{P} \mu\conWeight+  a(x) - a(x + \alpha_{P} d_{x}) \|_{\infty} \le  \alpha_{P} \mu \|  \conWeight \|_{\infty} +  \| a(x) - a(x + \alpha_{P} d_{x}) \|_{\infty} \le \theta \min_i\{ s_{i} \},
$$
where the first equality holds by \eqref{eq:slackVarUpdate} and final inequality holds by \eqref{eq:a-bound} and \eqref{eq:alpha-bound}.
Since $\theta \le 1 - \parFracBoundary$ the fraction to the boundary rule~\eqref{fracBoundary} is satisfied. Note that using the definition of $\theta$ from \eqref{min-step-size-aggresssive} and that $\parComp < \parCompAgg$ we get
$$
\frac{s^{+} Y}{\mu} \in [\parComp / \parCompAgg, \parCompAgg / \parComp]  \frac{s Y}{\mu} \subseteq  [\parComp, 1/\parComp ] e
$$
therefore $\alpha_{D} = 0$ gives a feasible dual iterate. We obtain a contradiction, because the step should have been accepted.
\end{proof}

\subsection{Convergence results for stabilization steps}

\subsubsection{Proof of Lemma~\ref{lem:compact-Q}} \label{sec:lem:compact-Q}

Note that during Lemma~\ref{lem:compact-Q} we will repeatedly use that the following elementary real analysis fact: 

\begin{fact}
If $g_i$ is a continuous function and the set $X = \{ x : g_i(x) \le 0 \}$ is bounded, then the set $X$ is compact
\end{fact}

\lemCompactQ*

\begin{proof}
First consider the set
$$
Q := \left\{ x \in \R^{\nvar} : (y, s) \in \R^{\ncon++} \times \R^{\ncon++}, \phi_{\mu}(x,y,s) \le C, \| \max\{ a(x), e \} \|_{\infty} \ge \max\{1,-f(x) \} \TOLunbounded \right\} 
$$
Now, consider some $x \in Q$. Recall that
$$
\phi_{\mu}(x, y, s) = f(x) + \mu \left( \parRegularizer \sum_{i = 1}^{\nvar} \sqrt{x_i^2 + 1 / \parRegularizer^2} - \parConRegularizer e^T a(x) \right)  - \mu  \sum_i{ \log \left( \vioVar \conWeight_i - a_i(x)  \right) } + \frac{\| S y - \mu \|_{\infty}^3}{\mu^2}.
$$
The expression $\parConRegularizer a_i(x) - \log(\mu \conWeight_i - a_i(x))$ and $\frac{\| S y - \mu \|^3}{\mu^2}$ are bounded from bellow. Therefore there exists some constant $K_{1} > 0$ such that
$$
-K_{1} \le f(x) \le K_{1} - \parRegularizer \sum_{i}{\sqrt{x_i^2 + 1 / \parRegularizer^2}}
$$
It follows that $x$ is bounded and therefore $Q$ is bounded. Furthermore, since $\phi_{\mu}(x) \le C$ and $Q$ is bounded there exists some constant $K_{2} > 0$ such that
$$
\mu w - a(x) \ge K_{2}
$$
for all $x \in Q$. Consider some sequence $x^{k} \in Q$ with $x^{k} \rightarrow x^{*}$. The statement $a(x) \le \mu w - K_{2}$ implies $\phi_{\mu}$ is continuous in a neighborhood of $x^{*}$. Using the definition of $Q$ and the assumption that $f$ and $a$ are continuous implies $x^{*} \in Q$ i.e. $Q$ is compact. 


%Using the fact that $Q$ is compact and $s > 0$ we deduce that $S^{-1} e$ is bounded, it follows that
Note that:
$$
\mathbb{Q}_{\mu, C} = \left\{ (x,y,s) \in \R^{\nvar} \times \R^{\ncon++} \times \R^{\ncon++} : x \in Q, a(x) + s = \mu \conWeight, \frac{S y}{\mu} \in [\parComp e, e / \parComp]\right\}.
$$
Consider some $(x,y,s) \in \mathbb{Q}_{\mu, C}$, since $s = \mu w - a(x) \ge K_{2}$ and $\frac{S y}{\mu} \in [\parComp e, e / \parComp]$ we can deduce $y$ is bounded. Since the function $a(x)$ and $S y$ are continuous we conclude $\mathbb{Q}_{\mu, C}$ is compact.
\end{proof}

\begin{restatable}{corollary}{coroBoundEverything}\label{coro:bound-everything}
Let the functions $f : \R^{\nvar} \rightarrow \R$ and $a : \R^{\nvar} \rightarrow \R^{\ncon}$ be twice differentiable. Consider some fixed $\mu > 0$.
Then there exists some $L > 0$ such that for all $(x, y, s) \in \mathbb{Q}_{\mu, C}$ the following inequalities hold:
$$
s_i, y_i \ge 1/L
$$
$$
\| x \|, \| y \|, \| s \|, \| \nabla \barrier_{\mu}(x) \|, \| \schur \|, \| \nabla a(x) \| \le L
$$
and for any $d$ s.t. $\| d \| < 1 / L$
\begin{subequations}\label{lipschitz-continuous}
\begin{flalign}
\barrier_{\mu}(x + d) &\le \barrier_{\mu}(x) + \nabla \barrier_{\mu}(x)^T d + L / 2 \| d \|^2 \label{phi-lipschitz-continuous} \\
\| a(x + d) - a(x) \| &\le L  \| d \|. \label{a-lipschitz-continuous}
\end{flalign}
\end{subequations}

Furthermore, if the aggressive criterion~\eqref{agg-criteron} does not holds:
$$
\max\{ \| \nabla \barrier_{\mu}(x) \|, \| S y - \mu \|_{\infty} \} \ge 1 / L
$$
\end{restatable}

\begin{proof}
All these claims use Lemma~\ref{lem:compact-Q} and the elementary real analysis fact that for any continuous function $g$ on a compact set there $X$ there exists some $x_{*} \in X$ such that $g(x_{*}) = \sup_{x \in X}{g(x)}$.

The only non-trivial claim is showing \eqref{lipschitz-continuous}, which proceed to show. Since there exists some constants $\varepsilon_{1} > 0$ such that $(x,y,s) \in \mathbb{Q}_{\mu, C}$ we have $a(x) \le \mu w - \varepsilon_{1}$. It follows that there exists some constant $\varepsilon_2 > 0$ such that for all $\| d \| \le \varepsilon_2$ we have $a(x + d) < \mu w$. It follows that there exists some $L > 0$ such that $\| \nabla^2 \barrier_{\mu}(x) \| \le L$.

For some $x$ and $\nu$ with $\| \nu \| = 1$ define the one dimensional function
$$
h(\alpha) :=  \barrier_{\mu}(x + \alpha \nu) 
$$
then for $\alpha \in [0, \varepsilon_2]$ we get
$$
h(\alpha) - h(0) - \alpha h'(0) = \int_{0}^{\alpha}{ \int_{0}^{\eta_{2}}{h''(\eta) \partial \eta_{1} \partial \eta_{2}} } \le \alpha^2 L / 2,
$$
which using $d = \nu \alpha$ for $\alpha \in [0, \varepsilon_2]$ concludes the proof of \eqref{phi-lipschitz-continuous}. Showing \eqref{a-lipschitz-continuous} consists of a simpler version of the argument for \eqref{phi-lipschitz-continuous}.
\end{proof}

With Corollary~\ref{coro:bound-everything} in hand we proceed to showing for sufficiently large $\delta$, Algorithm~\ref{alg:stable} will succeed.
%that there will only be a finite number of stabilization steps until the next aggressive step.


\subsubsection{Proof of Corollary~\ref{coroConsecutiveStable}}\label{sec:coroConsecutiveStable}

Using Lemma~\ref{lem:stable-succeed-for-large-delta} we can prove Corollary~\ref{sec:coroConsecutiveStable}. Lemma~\ref{lem:stable-succeed-for-large-delta} states that

\begin{restatable}{lemma}{lemStableSucceedForLargeDelta} \label{lem:stable-succeed-for-large-delta}
Let the functions $f : \R^{\nvar} \rightarrow \R$ and $a : \R^{\nvar} \rightarrow \R^{\ncon}$ be twice differentiable. There exists some $\bar{\delta} > 0$ such that for any $(x,y,s) \in \mathbb{Q}_{\mu,C}$ and $\delta \in [\bar{\delta}, \infty)$ the following statement holds. If Algorithm~\ref{one-phase-IPM} calls Algorithm~\ref{alg:stable} on the first inner iteration at the point $(x, y, s, \mu)$, then Algorithm~\ref{alg:stable}  terminates with $\status = \success$.
\end{restatable}

The proof of Lemma~\ref{lem:stable-succeed-for-large-delta} is deferred to Section~\ref{sec:lem:stable-succeed-for-large-delta}.

\coroConsecutiveStable*

\begin{proof}
Suppose in order to obtain a contradiction there is a infinite sequence of consecutive stabilization steps. Then there are two possibilities (i) there is an infinite sequence of consecutive steps where the sufficient decrease in the augmented log barrier function \eqref{phi-sufficient-progress} is satisfied or (ii) there is an infinite subsequence of stabilization steps where a sufficient decrease in the KKT error \eqref{eq:kkt-progress} is satisfied.

Since the unboundedness termination criterion~\eqref{terminate-dual-infeasible} is not met, we know by Lemma~\ref{lem:compact-Q} there exists some compact set $\mathbb{Q}_{\mu,C}$ that contains all the iterates.

Consider case (i). Consider any $\bar{\delta} > 0$ as defined in Lemma~\ref{lem:stable-succeed-for-large-delta}. Lemma~\ref{lem:stable-succeed-for-large-delta} implies a step will be taken with $\delta \le \parDeltaIncreaseFailure \bar{\delta}$. Now, consider any such step $(x,y,s)$ to $(x^{+}, y^{+}, s^{+})$ with step size $\alpha_{P}$. Using that the aggressive criterion~\eqref{agg-criteron} is not satisfied and that $\| \schur(x,y,s, \mu) \|$ is bounded on the compact set $\mathbb{Q}_{\mu,C}$, we deduce there exists some constant $K > 0$ such that $\tilde{\Delta}^{\phi_{\mu}}_{(x,y)}(\alpha_{P} d_{x}, \alpha_{P} d_{y}) < K$ for all $\delta \le \parDeltaIncreaseFailure \bar{\delta}$ and $\alpha_{P} > \parMinStableStepSize$ \todo{moves a little to quick}. Since the criterion for sufficient progress on the augmented log barrier function \eqref{phi-sufficient-progress} is satisfied, we deduce there exists some constant $K > 0$ such that $\phi_{\mu}(x^{+}, y^{+}, s^{+}) \le \phi_{\mu}(x, y, s) - K$ at each iteration, which implies eventually the unboundedness criterion~\eqref{terminate-dual-infeasible} is met. 

Consider case (ii). Since \eqref{eq:kkt-progress} holds for an infinite subsequence $(x^{k}, y^{k}, s^{k})$ and $\alpha_{P} > \parMinStableStepSize$ by \eqref{eq:min-step-size-stable} we have $K_{\mu}(x^{k}, y^{k}, s^{k}) \rightarrow 0$. This implies eventually the aggressive criterion~\eqref{agg-criteron} is met.

Therefore neither case (i) or (ii) is possible. By contradiction the result holds.
\end{proof}


\subsubsection{Proof of Lemma~\ref{lem:stable-succeed-for-large-delta}}\label{sec:lem:stable-succeed-for-large-delta}

Before we prove Lemma~\ref{lem:stable-succeed-for-large-delta} we prove two sub-lemmas.

\begin{restatable}{lemma}{lemLogBarrierLargeDelta} \label{lem:log-barrier-large-delta}
Let the functions $f : \R^{\nvar} \rightarrow \R$ and $a : \R^{\nvar} \rightarrow \R^{\ncon}$ be twice differentiable. Consider any fixed $\mu > 0$.
There exists some $c_{1}, c_{2}, \bar{\delta} > 0$ such that for any $(x,y,s) \in \mathbb{Q}_{\mu,C}$ and $\delta \in [\bar{\delta}, \infty)$ the following statement holds. If Algorithm~\ref{one-phase-IPM} calls Algorithm~\ref{alg:stable} on the first inner iteration at the point $(x, y, s, \mu)$, then the computed direction satisfies 
$$
\barrier_{\mu} (x + d_{x}) \le \barrier_{\mu} (x) + \parObjReductFactor \tilde{\Delta}^{\barrier_{\mu}}_{(x,y)}( d_{x} ) - c_1 \| \nabla \barrier_{\mu} (x) \|^2
$$
%and if $\delta \in [0, \parDeltaIncreaseFailure \bar{\delta}]$ then:
%$$
% \tilde{\Delta}^{\barrier_{\mu}}_{(x,y)}( \alpha_{P} d_{x} ) \le -c_{2} \| \nabla \barrier_{\mu}(x) \|^2
%$$
\end{restatable}



\begin{proof}
Recall the matrix $\schur$ as defined in \eqref{eq:schur-matrix}.

Consider some $c_{2} \in (\parObjReductFactor, 1)$ then there exists some constant $C > 0$ such that for all $\delta$ greater than
$C \left( \| \schur \| + \| \nabla \barrier_{\mu}(x) \| \right)$, we have:
\begin{flalign}\label{eq:C-big-enough}
 \lambda_{\min}  / \lambda_{\max} \le \sqrt{c_{2}}, 1 - L \lambda_{\max} / \lambda_{\min}^2 \ge \sqrt{c_{2}}, \| d_{x} \| < 1 / L
\end{flalign}
where $\lambda_{\min}$ and $\lambda_{\max}$ denote the smallest and largest eigenvalues of the matrix $H = \schur + \delta I$.


Now,
\begin{flalign*}
\barrier_{\mu}(x + d_{x}) - \barrier_{\mu}(x) - \frac{\parObjReductFactor}{2} d_{x}^T \schur d_{x}
&\le_{(i)}   \nabla \barrier_{\mu}(x)^T d_{x} + L \| d_{x} \|^2 \\
 &=_{(ii)} -\nabla \barrier_{\mu}(x)^T H^{-1} \nabla \barrier_{\mu}(x) + L  \nabla \barrier_{\mu}(x)^T H^{-2} \nabla \barrier_{\mu}(x) \\
  &\le_{(iii)} -\| \nabla \barrier_{\mu}(x) \|^2 / \lambda_{\max} (1  - L \lambda_{\max} /  \lambda_{\min}^2) \\
  &\le_{(iv)} -c_{2} \| \nabla \barrier_{\mu}(x) \|^2 / \lambda_{\min} \\
  &=_{(v)} -\parObjReductFactor  \| \nabla \barrier_{\mu}(x) \|^2 / \lambda_{\min} - (c_{2} - \parObjReductFactor) / \lambda_{\min} \| \nabla \barrier_{\mu}(x) \|^2  \\
    &\le_{(vi)}  - \parObjReductFactor \nabla \barrier_{\mu}(x)^T H^{-1} \nabla \barrier_{\mu}(x) - (c_{2} - \parObjReductFactor)  / \lambda_{\min}   \| \nabla \barrier_{\mu}(x) \|^2 \\
    &=_{(vii)}  - \parObjReductFactor \nabla \barrier_{\mu}(x)^T d_{x} - (c_{2} - \parObjReductFactor)  / \lambda_{\min}   \| \nabla \barrier_{\mu}(x) \|^2 \\
\end{flalign*}
where:
\begin{enumerate}[label=(\roman*)]
\item holds by Corollary~\ref{coro:bound-everything} and equation~\eqref{eq:C-big-enough}
\item using $H d_{x} = -\nabla \barrier_{\mu}(x)$
\item $\| v \|^2 / \lambda_{\min} \ge v^T H^{-1} v \ge \| v \|^2 / \lambda_{\max}$ for any $v$
\item By equation~\eqref{eq:C-big-enough}
\item Expanding
\item $\| v \|^2 / \lambda_{\min} \ge v^T H^{-1} v $ for any $v$.
\item using $H d_{x} = -\nabla \barrier_{\mu}(x)$
\end{enumerate}

Since $\frac{c_{2} - \parObjReductFactor}{\lambda_{\min}} > 0$, we have proved the claim.
\end{proof}

\begin{restatable}{lemma}{lemCompLargeDelta} \label{lem:comp-large-delta}
Let the functions $f : \R^{\nvar} \rightarrow \R$ and $a : \R^{\nvar} \rightarrow \R^{\ncon}$ be twice differentiable. Consider any fixed $\mu > 0$
and $c_{1} > 0$. There exists some $\bar{\delta} > 0$ such that for any $(x,y,s) \in \mathbb{Q}_{\mu,C}$ and $\delta \in [\bar{\delta}, \infty)$ the following statement holds. If Algorithm~\ref{one-phase-IPM} calls Algorithm~\ref{alg:stable} on the first inner iteration at the point $(x, y, s, \mu)$, then the computed direction and trial point $(x^{+}, y^{+}, s^{+}, \mu)$ corresponding to $\alpha_{P} = 1$ satisfies
%a new point $(x^{+}, y^{+}, s^{+})$ with:
\begin{flalign}
s + d_{s} &\ge \parFracBoundaryMax s \label{eq-lem:frac-boundary-max} \\
s^{+} &\ge  \parFracBoundary s \label{eq-lem:frac-boundary} \\
S^{+} y^{+} &\in [\mu e \parComp, \mu e/\parComp] 
\end{flalign}
Furthermore,
$$
\MeritComp(x^{+},y^{+}) \le \MeritComp(x,y) +  \parObjReductFactor \tilde{\Delta}^{\MeritComp}_{(x,y)}( d_{x}, d_{y} ) + \left( c_{1} -  \MeritComp(x,y) (1 - \parObjReductFactor) \right)
$$
\end{restatable}

\begin{proof}
Consider any $\gamma \in (0,1)$ and define
$$
\bar{\delta}_{2}(x,s,y) = \lambda_{\min} ( \schur ) + 1 / \gamma
$$
Let $q( x, s, y)$ be some function $q : \mathbb{Q}_{\mu,C} \rightarrow \R$  and recall $\mu > 0$ is fixed.
We use the notation $q = O(\gamma)$ to denote that there exists some constant $K > 0$ such that  $q(x, s, y) \le K \gamma$ each time Algorithm~\ref{one-phase-IPM} calls Algorithm~\ref{alg:stable} on the first inner iteration.


Then for any $\delta \ge \bar{\delta}_{2}(x,s,y)$ we have:
$$
\| d_{x} \| = O(\gamma)
$$
Hence by Corollary~\ref{coro:bound-everything} we have:
\begin{flalign*}
\| S^{-1} d_{s}  \|_{\infty} = O( \gamma ) \\
\| S^{-1} (S^{+} - S)  \|_{\infty} = O( \gamma ) 
\end{flalign*}
which for sufficiently small $\gamma$ implies \eqref{eq-lem:frac-boundary-max} and \eqref{eq-lem:frac-boundary}.

Furthermore,
\begin{flalign*}
\| Y^{-1} d_{y} \|_{\infty} &= \| \mu  (Y S)^{-1}  e - e + S^{-1} d_{s}  \|_{\infty} \\
&\le (1 / \parComp - 1) + \| S^{-1} d_{s}  \|_{\infty} \le 1 / \parComp + O(\gamma)
\end{flalign*}
Therefore:
\begin{flalign*}
\| \mu - S^{+} y^{+} \|_{\infty} &\le \| \mu - S^{+} (y + d_{y}) \|_{\infty} \\
 &\le \| \mu - S (y + d_{y}) \|_{\infty}  +  \| (S - S^{+}) (y + d_{y}) \|_{\infty} \\
 &=  \| Y d_{s} \|_{\infty} +  \| (S - S^{+}) (y + d_{y}) \|_{\infty} \\
 &= O(\gamma)
\end{flalign*}
Where the first inequality follows from $\alpha_{P} = 1$ from \eqref{eq:alphaD-least-squares} and the second inequality by the triangle inequality, the third by $\mu - S y + S d_{y} + Y d_{s} = 0$ and the fourth by $\| s - s^{+} \| = O(\gamma)$ and $\| d_{s} \| = O(\gamma)$. Hence

$$
\MeritComp(x^{+},y^{+}) = \frac{\| \mu - S^{+} y^{+} \|_{\infty}^3 }{\mu^2} = O( \gamma^3 ).
$$
Since:
$$
\MeritComp(x,y) +  \tilde{\Delta}^{\MeritComp}_{(x,y)}( d_{x}, d_{y} ) = 0
$$
the result holds.
\end{proof}


\lemStableSucceedForLargeDelta*

\begin{proof}
There exists some $c_{2} > 0$ such that 
$$
c_{2} -  \MeritComp(x,y) / 2 - c_{1} \| \nabla \barrier_{\mu} (x) \|^2 \le 0
$$
for all $(x, y, s) \in \mathbb{Q}_{\mu,C}$. Combining Lemmas~\ref{lem:log-barrier-large-delta} and \ref{lem:comp-large-delta} we conclude that there exists some $\bar{\delta}$ such that for all $\delta \ge \bar{\delta}$
\begin{flalign}
\tilde{\Delta}^{\phi_{\mu}}_{(x,y)}(u, v) = \tilde{\Delta}^{\barrier_{\mu}}_{(x,y)}( u ) +   \tilde{\Delta}^{\MeritComp}_{(x,y)}( u, v ).
\end{flalign}

\end{proof}


\section{Matrix factorization strategy}

This strategy is based on the ideas of IPOPT \cite[Algorithm IC]{wachter2006implementation}.

\begin{algorithm}[H]
\textbf{Input:} The matrix $\mathcal{K}_{0}$ and current delta choice $\delta$ \\
\textbf{Output:} The factorization $\mathcal{K}_{\delta}^{-1}$ for some $\delta > 0$ such that the matrix $\mathcal{K}_{\delta}$ has the correct inertia.
\begin{enumerate}[label*=A.{\arabic*}]
\item Set $\delta_{\text{prev}} \gets \delta$
\item Set $\delta \gets 0$
\item Perform LDL factorization of $\mathcal{K}_{\delta}$, if inertia is correct return $\mathcal{K}_{\delta}^{-1}$ otherwise continue.
\item If $\delta_{prev} > 0$ set $\delta \gets \max\{ \parDeltaMin, \delta_{\text{prev}} / 3 \}$ otherwise set $\delta = \delta_{\text{start}} \mu$.
\item Perform LDL factorization of $\mathcal{K}_{\delta}$, if inertia is correct return $\mathcal{K}_{\delta}^{-1}$ otherwise continue.
\item Set $\delta \gets 8 \delta$. Go to previous step.
\end{enumerate}
\caption{Matrix factorization strategy}\label{alg:mat-fact}
\end{algorithm}

\section{The (non-existence) of a central path in non-convex optimization}\label{app:non-existence-of-central-path}

Would be nice to have a long discussion on this issue

$$
f_{\mu}(x) = 50 (x - 0.5)^3 + x - \mu (\log(x) + \log(1 - x))
$$

$$
\nabla f_{\mu}(x) = 150.0 * (x - 0.5)^2 + 1.0  - \mu / x + \mu / (1 - x) = 0 \\
$$
Is discontinuous at $\mu = 3$, $x \approx 0.5$ i.e. there exists no function $x(\mu)$ such that $\nabla f_{\mu}(x(\mu)) = 0$ and $x(\mu)$ is continuous. 

[Vanderbei' s example for the problem $\min{ x -x^2}$ s.t. $x \ge 0$ there exists no continuous central path from an initial point to the optimal solution. However, optimal solution is unbounded.]


\end{document}